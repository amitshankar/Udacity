{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "https://stackoverflow.com/questions/14325654/how-to-use-python-markdown-to-process-a-file-that-is-read-in\n",
    "https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "https://stackoverflow.com/questions/14560863/python-join-with-newline\n",
    "https://stackoverflow.com/questions/743806/how-to-split-a-string-into-a-list\n",
    "https://stackabuse.com/reading-and-writing-lists-to-a-file-in-python/\n",
    "https://stackoverflow.com/questions/6996603/delete-a-file-or-folder\n",
    "https://stackoverflow.com/questions/5214578/python-print-string-to-text-file\n",
    "https://stackoverflow.com/questions/89228/calling-an-external-command-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #to run commands in command prompt in python\n",
    "import glob # to get paths to files in a folder\n",
    "import shutil #copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print('Creating Directory '+directory)\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "folder structure\n",
    "\n",
    "clean_md_file.ipynb\n",
    "project_03_01.ipynb\n",
    "data>>\n",
    "git_page>>project_03_01.md\n",
    "git_page>>images>>movie_data_eda>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrangle_act_v2_0.ipynb\n",
      "data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0.md\n",
      "data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0_files\n",
      "data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "#enter the ipython notebook name\n",
    "#notebook_name='project_03_01.ipynb'\n",
    "#markdown_name='project_03_01.md'\n",
    "#images_folder_name=markdown_name.replace('.md','')+'_files' #remove the .md and add _files\n",
    "#subfolder_name='project_03_01' # images/'subfolder_name'/ -- this will contain all images\n",
    "\n",
    "#data_analyst_nanodegree_term_02_project_01_perceptual_phenomenon_python_004\n",
    "#data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0\n",
    "notebook_name='wrangle_act_v2_0.ipynb'\n",
    "markdown_name='data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0.md'\n",
    "images_folder_name=markdown_name.replace('.md','')+'_files' #remove the .md and add _files\n",
    "subfolder_name='data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0' # images/'subfolder_name'/ -- this will contain all images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(notebook_name) # name of jupyter notebook\n",
    "print(markdown_name) #md file made during jupyter to md conversion, moved to git_page folder and deleted from root\n",
    "print(images_folder_name) #default folder made when generating md file - later deleted\n",
    "print(subfolder_name) #name of the subfolder inside images subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Directory git_page/images/data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0\n"
     ]
    }
   ],
   "source": [
    "#create the directory structure\n",
    "create_dir('git_page/images/'+subfolder_name) #subfolder for all project images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter nbconvert wrangle_act_v2_0.ipynb --to markdown --output data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0.md\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert project_03_01.ipynb --to markdown --output test.md\n",
    "## first create a string using the notebook name and markdown name\n",
    "string_01='jupyter nbconvert '+ notebook_name + ' --to markdown --output '+ markdown_name\n",
    "#string_01='jupyter nbconvert '+ notebook_name + ' --to markdown' \n",
    "\n",
    "print(string_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the string_01 in command prompt to generate the markdown files\n",
    "os.system(string_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a list of only image names in sub directory\n",
    "#image_links = [f for f in glob.glob(\"markdown\\*.png\")]\n",
    "\n",
    "images_path=images_folder_name+'\\*.png'\n",
    "image_links = [f for f in glob.glob(images_path)]\n",
    "\n",
    "image_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from the image_links, only save the image names\n",
    "#save just the image names to a list\n",
    "image_names=[]\n",
    "for i in image_links:\n",
    "    #image_names.append(i.replace('markdown\\\\',''))\n",
    "    image_names.append(i.replace(images_folder_name+'\\\\',''))\n",
    "    \n",
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '# Wrangle Report\\n',\n",
       " '\\n',\n",
       " '   \\n',\n",
       " \"**Table of Contents**<a id='Top'><a>   \\n\",\n",
       " '[Reference](#Reference)  \\n',\n",
       " '[A. Data Gathering Efforts](#A)  \\n',\n",
       " '[B. Data Access Issues](#B)  \\n',\n",
       " '[C. Data Cleaning](#C)\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " \"<a id='Reference'></a>\\n\",\n",
       " '[Top](#Top)\\n',\n",
       " '# Reference \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'https://stackoverflow.com/questions/32400867/pandas-read-csv-from-url  \\n',\n",
       " 'https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object3\\n',\n",
       " 'https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file\\n',\n",
       " 'https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file\\n',\n",
       " 'https://stackoverflow.com/questions/41001973/python-3-5-1-nameerror-name-json-is-not-defined\\n',\n",
       " 'https://stackoverflow.com/questions/27900451/convert-tweepy-status-object-into-json\\n',\n",
       " 'https://gist.github.com/yanofsky/5436496\\n',\n",
       " 'https://stackoverflow.com/questions/11716380/python-beautifulsoup-extract-text-from-anchor-tag\\n',\n",
       " 'https://stackoverflow.com/questions/30522724/take-multiple-lists-into-dataframe\\n',\n",
       " 'https://stackoverflow.com/questions/15247628/how-to-find-duplicate-names-using-pandas  \\n',\n",
       " 'https://stackoverflow.com/questions/466345/converting-string-into-datetime\\n',\n",
       " 'https://stackoverflow.com/questions/33034559/how-to-remove-last-the-two-digits-in-a-column-that-is-of-integer-type\\n',\n",
       " 'https://stackoverflow.com/questions/25146121/extracting-just-month-and-year-from-pandas-datetime-column-python\\n',\n",
       " 'https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict\\n',\n",
       " 'https://stackoverflow.com/questions/39092067/pandas-dataframe-convert-column-type-to-string-or-categorical\\n',\n",
       " 'https://stackoverflow.com/questions/18792918/combine-two-pandas-data-frames-join-on-a-common-column\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '#import libraries\\n',\n",
       " 'import requests # reading files programmatically\\n',\n",
       " 'import os # manipulating file paths\\n',\n",
       " 'import pandas as pd\\n',\n",
       " 'import numpy as np\\n',\n",
       " 'import tweepy #read tweeter data -- pip install tweepy\\n',\n",
       " '#import simplejson as json # to make json dumps --  pip install simplejson\\n',\n",
       " 'import json # to create json objects \\n',\n",
       " 'import time # to calculate the execution times of functions\\n',\n",
       " 'from datetime import datetime\\n',\n",
       " '\\n',\n",
       " '# set seed for sampling\\n',\n",
       " 'np.random.seed(27)\\n',\n",
       " '\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " \"<a id='A'></a>\\n\",\n",
       " '[Top](#Top)\\n',\n",
       " '# A. Data Gathering Efforts \\n',\n",
       " '\\n',\n",
       " '## 1. Downloading the twitter-archive-enhanced.csv\\n',\n",
       " '\\n',\n",
       " 'The twitter-archive-enhanced.csv was saved to the local directory by clicking the following link https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv \\n',\n",
       " 'and saving the corresponding csv file in the local working directory. \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# read the twitter-archive-enhanced.csv file intp a pandas dataframe\\n',\n",
       " \"df_twitter_archive=pd.read_csv('twitter-archive-enhanced.csv')\\n\",\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# examine the dataframe\\n',\n",
       " 'df_twitter_archive.head(2)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '<div>\\n',\n",
       " '<style scoped>\\n',\n",
       " '    .dataframe tbody tr th:only-of-type {\\n',\n",
       " '        vertical-align: middle;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe tbody tr th {\\n',\n",
       " '        vertical-align: top;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe thead th {\\n',\n",
       " '        text-align: right;\\n',\n",
       " '    }\\n',\n",
       " '</style>\\n',\n",
       " '<table border=\"1\" class=\"dataframe\">\\n',\n",
       " '  <thead>\\n',\n",
       " '    <tr style=\"text-align: right;\">\\n',\n",
       " '      <th></th>\\n',\n",
       " '      <th>tweet_id</th>\\n',\n",
       " '      <th>in_reply_to_status_id</th>\\n',\n",
       " '      <th>in_reply_to_user_id</th>\\n',\n",
       " '      <th>timestamp</th>\\n',\n",
       " '      <th>source</th>\\n',\n",
       " '      <th>text</th>\\n',\n",
       " '      <th>retweeted_status_id</th>\\n',\n",
       " '      <th>retweeted_status_user_id</th>\\n',\n",
       " '      <th>retweeted_status_timestamp</th>\\n',\n",
       " '      <th>expanded_urls</th>\\n',\n",
       " '      <th>rating_numerator</th>\\n',\n",
       " '      <th>rating_denominator</th>\\n',\n",
       " '      <th>name</th>\\n',\n",
       " '      <th>doggo</th>\\n',\n",
       " '      <th>floofer</th>\\n',\n",
       " '      <th>pupper</th>\\n',\n",
       " '      <th>puppo</th>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </thead>\\n',\n",
       " '  <tbody>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>0</th>\\n',\n",
       " '      <td>892420643555336193</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>2017-08-01 16:23:56 +0000</td>\\n',\n",
       " '      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n',\n",
       " \"      <td>This is Phineas. He's a mystical boy. Only eve...</td>\\n\",\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n',\n",
       " '      <td>13</td>\\n',\n",
       " '      <td>10</td>\\n',\n",
       " '      <td>Phineas</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>1</th>\\n',\n",
       " '      <td>892177421306343426</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>2017-08-01 00:17:27 +0000</td>\\n',\n",
       " '      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n',\n",
       " \"      <td>This is Tilly. She's just checking pup on you....</td>\\n\",\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n',\n",
       " '      <td>13</td>\\n',\n",
       " '      <td>10</td>\\n',\n",
       " '      <td>Tilly</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </tbody>\\n',\n",
       " '</table>\\n',\n",
       " '</div>\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# examine the dataframe structure\\n',\n",
       " 'df_twitter_archive.info()\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " \"    <class 'pandas.core.frame.DataFrame'>\\n\",\n",
       " '    RangeIndex: 2356 entries, 0 to 2355\\n',\n",
       " '    Data columns (total 17 columns):\\n',\n",
       " '    tweet_id                      2356 non-null int64\\n',\n",
       " '    in_reply_to_status_id         78 non-null float64\\n',\n",
       " '    in_reply_to_user_id           78 non-null float64\\n',\n",
       " '    timestamp                     2356 non-null object\\n',\n",
       " '    source                        2356 non-null object\\n',\n",
       " '    text                          2356 non-null object\\n',\n",
       " '    retweeted_status_id           181 non-null float64\\n',\n",
       " '    retweeted_status_user_id      181 non-null float64\\n',\n",
       " '    retweeted_status_timestamp    181 non-null object\\n',\n",
       " '    expanded_urls                 2297 non-null object\\n',\n",
       " '    rating_numerator              2356 non-null int64\\n',\n",
       " '    rating_denominator            2356 non-null int64\\n',\n",
       " '    name                          2356 non-null object\\n',\n",
       " '    doggo                         2356 non-null object\\n',\n",
       " '    floofer                       2356 non-null object\\n',\n",
       " '    pupper                        2356 non-null object\\n',\n",
       " '    puppo                         2356 non-null object\\n',\n",
       " '    dtypes: float64(4), int64(3), object(10)\\n',\n",
       " '    memory usage: 313.0+ KB\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '## Observation\\n',\n",
       " 'The df_twitter_archive dataframe has 17 variables and 2356 observations. Some of the variables have missing values.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '## 2. Downloading programmatically the image_predictions.tsv file\\n',\n",
       " '\\n',\n",
       " 'The image_predictions.tsv was programmatically downloaded from https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv using the requests funciton.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# programmatically download the image_predictions.tsv file\\n',\n",
       " \"url='https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\\n\",\n",
       " 'response=requests.get(url) # saves the file in the memory\\n',\n",
       " '\\n',\n",
       " '# view the file in the memory\\n',\n",
       " '# response.content\\n',\n",
       " '\\n',\n",
       " '# create the file name by truncating the file name from the end of the url\\n',\n",
       " \"file_name=url.split('/')[-1] #'image-predictions.tsv'\\n\",\n",
       " '\\n',\n",
       " '# write the tsv file to the working directory \\n',\n",
       " \"with open(file_name, mode='wb') as file:\\n\",\n",
       " '    file.write(response.content)\\n',\n",
       " '    \\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# read the image-predictions.tsv file into a pandas file\\n',\n",
       " \"df_image_predictions=pd.read_csv('image-predictions.tsv', sep = '\\\\t', encoding = 'utf-8')\\n\",\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# examine the image_predictions_df dataframe\\n',\n",
       " 'df_image_predictions.head(2)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '<div>\\n',\n",
       " '<style scoped>\\n',\n",
       " '    .dataframe tbody tr th:only-of-type {\\n',\n",
       " '        vertical-align: middle;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe tbody tr th {\\n',\n",
       " '        vertical-align: top;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe thead th {\\n',\n",
       " '        text-align: right;\\n',\n",
       " '    }\\n',\n",
       " '</style>\\n',\n",
       " '<table border=\"1\" class=\"dataframe\">\\n',\n",
       " '  <thead>\\n',\n",
       " '    <tr style=\"text-align: right;\">\\n',\n",
       " '      <th></th>\\n',\n",
       " '      <th>tweet_id</th>\\n',\n",
       " '      <th>jpg_url</th>\\n',\n",
       " '      <th>img_num</th>\\n',\n",
       " '      <th>p1</th>\\n',\n",
       " '      <th>p1_conf</th>\\n',\n",
       " '      <th>p1_dog</th>\\n',\n",
       " '      <th>p2</th>\\n',\n",
       " '      <th>p2_conf</th>\\n',\n",
       " '      <th>p2_dog</th>\\n',\n",
       " '      <th>p3</th>\\n',\n",
       " '      <th>p3_conf</th>\\n',\n",
       " '      <th>p3_dog</th>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </thead>\\n',\n",
       " '  <tbody>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>0</th>\\n',\n",
       " '      <td>666020888022790149</td>\\n',\n",
       " '      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\\n',\n",
       " '      <td>1</td>\\n',\n",
       " '      <td>Welsh_springer_spaniel</td>\\n',\n",
       " '      <td>0.465074</td>\\n',\n",
       " '      <td>True</td>\\n',\n",
       " '      <td>collie</td>\\n',\n",
       " '      <td>0.156665</td>\\n',\n",
       " '      <td>True</td>\\n',\n",
       " '      <td>Shetland_sheepdog</td>\\n',\n",
       " '      <td>0.061428</td>\\n',\n",
       " '      <td>True</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>1</th>\\n',\n",
       " '      <td>666029285002620928</td>\\n',\n",
       " '      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\\n',\n",
       " '      <td>1</td>\\n',\n",
       " '      <td>redbone</td>\\n',\n",
       " '      <td>0.506826</td>\\n',\n",
       " '      <td>True</td>\\n',\n",
       " '      <td>miniature_pinscher</td>\\n',\n",
       " '      <td>0.074192</td>\\n',\n",
       " '      <td>True</td>\\n',\n",
       " '      <td>Rhodesian_ridgeback</td>\\n',\n",
       " '      <td>0.072010</td>\\n',\n",
       " '      <td>True</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </tbody>\\n',\n",
       " '</table>\\n',\n",
       " '</div>\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# examine the structure of the df_image_predictions dataframe\\n',\n",
       " 'df_image_predictions.info()\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " \"    <class 'pandas.core.frame.DataFrame'>\\n\",\n",
       " '    RangeIndex: 2075 entries, 0 to 2074\\n',\n",
       " '    Data columns (total 12 columns):\\n',\n",
       " '    tweet_id    2075 non-null int64\\n',\n",
       " '    jpg_url     2075 non-null object\\n',\n",
       " '    img_num     2075 non-null int64\\n',\n",
       " '    p1          2075 non-null object\\n',\n",
       " '    p1_conf     2075 non-null float64\\n',\n",
       " '    p1_dog      2075 non-null bool\\n',\n",
       " '    p2          2075 non-null object\\n',\n",
       " '    p2_conf     2075 non-null float64\\n',\n",
       " '    p2_dog      2075 non-null bool\\n',\n",
       " '    p3          2075 non-null object\\n',\n",
       " '    p3_conf     2075 non-null float64\\n',\n",
       " '    p3_dog      2075 non-null bool\\n',\n",
       " '    dtypes: bool(3), float64(3), int64(2), object(4)\\n',\n",
       " '    memory usage: 152.1+ KB\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '## Observation\\n',\n",
       " '\\n',\n",
       " 'The df_image_predictions has 12 variables and 2075 observations. The are no missing values in the dataframe.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '## 3. Downloading Twitter data via Twitter API and tweepy library\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '## set tweet consumer and access key >>> replace the ### with actual keys\\n',\n",
       " \"consumer_key = 'Yn71UCiC2MdIHkBalOBc08yMO'\\n\",\n",
       " \"consumer_secret = 'K7CAtE6njCkEA3trt592jJEBDRa0a6OkZsoV6MsdkM8BLWPSCl'\\n\",\n",
       " \"access_token = '108732090-QR9V8gfQGTPu6tJBzNkINGhKjCTMh0vhuOziyoe3'\\n\",\n",
       " \"access_secret = 'HsALvm8Y5qG77fTMrfGeWjVYZY6DnupdoZu4FSBnaUmk2'\\n\",\n",
       " '\\n',\n",
       " 'auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\\n',\n",
       " 'auth.set_access_token(access_token, access_secret)\\n',\n",
       " '\\n',\n",
       " '# use jsonparser to make json readable content, create json dumps and query json objects\\n',\n",
       " '# wait_on_rate_limit = True , allows the program to wait during timeouts \\n',\n",
       " '# wait_on_rate_limit_notify = True, writes to screen when waiting\\n',\n",
       " 'api = tweepy.API(auth,parser=tweepy.parsers.JSONParser(),wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# function to append file line by line\\n',\n",
       " '# The function was adapted from https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file\\n',\n",
       " '# input: the function takes a filename string and text\\n',\n",
       " '# process: the function opens a file and adds the text in append mode\\n',\n",
       " '# out: none\\n',\n",
       " 'def FileSave(filename,content):\\n',\n",
       " '    with open(filename, \"a\") as myfile:\\n',\n",
       " '        myfile.write(content)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# input: the function takes a list of tweet ids and a filename\\n',\n",
       " '# process: the function downloads tweets corresponding to a tweet ids and adds it to a file\\n',\n",
       " '# out: the function prints out the time taken to download the tweets, prints the error msgs and\\n',\n",
       " '#      returns a list of ids that could not be downloaded\\n',\n",
       " '\\n',\n",
       " 'def download_tweets(id_list,filename):\\n',\n",
       " '    \\n',\n",
       " '    # set the start time\\n',\n",
       " '    start_time = time.time()\\n',\n",
       " '\\n',\n",
       " '    unloaded_tweet_ids=[]\\n',\n",
       " '    counter=0\\n',\n",
       " '    for i in id_list:\\n',\n",
       " '        try:\\n',\n",
       " \"            #print(counter,' >> Tweet id: ',i)\\n\",\n",
       " \"            tweet=api.get_status(i,tweet_mode='extended')\\n\",\n",
       " \"            FileSave(filename,json.dumps(tweet)+'\\\\n')\\n\",\n",
       " '            counter=counter+1\\n',\n",
       " '            \\n',\n",
       " '        except Exception as download_error_msg:\\n',\n",
       " \"            print(counter,' >> Tweet id: ',i)\\n\",\n",
       " '            print(download_error_msg)\\n',\n",
       " '            unloaded_tweet_ids.append(i)\\n',\n",
       " '            counter=counter+1\\n',\n",
       " '\\n',\n",
       " '            \\n',\n",
       " '    #print unloaded tweeter ids\\n',\n",
       " \"    print('\\\\n \\\\nTotal number of Tweeter ids :',len(id_list))\\n\",\n",
       " \"    print('The following ',len(unloaded_tweet_ids), 'tweet ids could not be downloaded for various reasons: ')\\n\",\n",
       " '    print(unloaded_tweet_ids)\\n',\n",
       " '    \\n',\n",
       " '    # set the end time\\n',\n",
       " '    end_time = time.time()\\n',\n",
       " '\\n',\n",
       " '    # print the execution time\\n',\n",
       " \"    print('\\\\n \\\\nThe download process took: ', (end_time - start_time)/60, ' minutes')\\n\",\n",
       " '    \\n',\n",
       " '    return(unloaded_tweet_ids)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# set the tweet ids that will be using in the api to access the actual data\\n',\n",
       " \"tweet_id=df_twitter_archive['tweet_id']\\n\",\n",
       " '\\n',\n",
       " '# download tweets by passing the tweet_id list and tweet_json.txt filename\\n',\n",
       " '# save the results of unloaded ids so they can be attempted again\\n',\n",
       " \"error_ids_01=download_tweets(tweet_id,'tweet_json.txt')\\n\",\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '    19  >> Tweet id:  888202515573088257\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    95  >> Tweet id:  873697596434513921\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    118  >> Tweet id:  869988702071779329\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    132  >> Tweet id:  866816280283807744\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    155  >> Tweet id:  861769973181624320\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    247  >> Tweet id:  845459076796616705\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    260  >> Tweet id:  842892208864923648\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    298  >> Tweet id:  837012587749474308\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    382  >> Tweet id:  827228250799742977\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    566  >> Tweet id:  802247111496568832\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    784  >> Tweet id:  775096608509886464\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    815  >> Tweet id:  771004394259247104\\n',\n",
       " \"    [{'code': 179, 'message': 'Sorry, you are not authorized to see this status.'}]\\n\",\n",
       " '    818  >> Tweet id:  770743923962707968\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '    Rate limit reached. Sleeping for: 732\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '    932  >> Tweet id:  754011816964026368\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '    Rate limit reached. Sleeping for: 728\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '    \\n',\n",
       " '     \\n',\n",
       " '    Total number of Tweeter ids : 2356\\n',\n",
       " '    The following  14 tweet ids could not be downloaded for various reasons: \\n',\n",
       " '    [888202515573088257, 873697596434513921, 869988702071779329, 866816280283807744, 861769973181624320, 845459076796616705, 842892208864923648, 837012587749474308, 827228250799742977, 802247111496568832, 775096608509886464, 771004394259247104, 770743923962707968, 754011816964026368]\\n',\n",
       " '    \\n',\n",
       " '     \\n',\n",
       " '    The download process took:  31.737418989340465  minutes\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# try to download the tweet contents corresponding the error tweets\\n',\n",
       " \"error_ids_02=download_tweets(error_ids_01,'tweet_json.txt')\\n\",\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '    0  >> Tweet id:  888202515573088257\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    1  >> Tweet id:  873697596434513921\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    2  >> Tweet id:  869988702071779329\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    3  >> Tweet id:  866816280283807744\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    4  >> Tweet id:  861769973181624320\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    5  >> Tweet id:  845459076796616705\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    6  >> Tweet id:  842892208864923648\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    7  >> Tweet id:  837012587749474308\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    8  >> Tweet id:  827228250799742977\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    9  >> Tweet id:  802247111496568832\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    10  >> Tweet id:  775096608509886464\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    11  >> Tweet id:  771004394259247104\\n',\n",
       " \"    [{'code': 179, 'message': 'Sorry, you are not authorized to see this status.'}]\\n\",\n",
       " '    12  >> Tweet id:  770743923962707968\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    13  >> Tweet id:  754011816964026368\\n',\n",
       " \"    [{'code': 144, 'message': 'No status found with that ID.'}]\\n\",\n",
       " '    \\n',\n",
       " '     \\n',\n",
       " '    Total number of Tweeter ids : 14\\n',\n",
       " '    The following  14 tweet ids could not be downloaded for various reasons: \\n',\n",
       " '    [888202515573088257, 873697596434513921, 869988702071779329, 866816280283807744, 861769973181624320, 845459076796616705, 842892208864923648, 837012587749474308, 827228250799742977, 802247111496568832, 775096608509886464, 771004394259247104, 770743923962707968, 754011816964026368]\\n',\n",
       " '    \\n',\n",
       " '     \\n',\n",
       " '    The download process took:  0.03408433596293132  minutes\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '## Observation\\n',\n",
       " '\\n',\n",
       " \"At this point, we have successfully saved each tweet's entire content in a tweet_json.txt file with each tweet in a new line.There were 13 tweets that could not be downloaded for various reasons.  \\n\",\n",
       " '\\n',\n",
       " \"Next, we will read the file into memory where each tweet will be saved into a separate element in a list called 'lines'. We will then iterate through the lines list and extract interesting elements such as tweet text, favourites count, retweet count etc in separate lists and later concatenate the lists into a dataframe.  \\n\",\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '## read json file to a list array and strip new line charactor\\n',\n",
       " \"lines = [line.rstrip('\\\\n') for line in open('tweet_json.txt')]\\n\",\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# read one tweet into a temp file to examine its content\\n',\n",
       " '# load the tweet into a json format for easier extraction of information\\n',\n",
       " 'tmp = json.loads(lines[0])\\n',\n",
       " '\\n',\n",
       " '# examine a tweet\\n',\n",
       " 'tmp\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " \"    {'contributors': None,\\n\",\n",
       " \"     'coordinates': None,\\n\",\n",
       " \"     'created_at': 'Tue Aug 01 16:23:56 +0000 2017',\\n\",\n",
       " \"     'display_text_range': [0, 85],\\n\",\n",
       " \"     'entities': {'hashtags': [],\\n\",\n",
       " \"      'media': [{'display_url': 'pic.twitter.com/MgUWQ76dJU',\\n\",\n",
       " \"        'expanded_url': 'https://twitter.com/dog_rates/status/892420643555336193/photo/1',\\n\",\n",
       " \"        'id': 892420639486877696,\\n\",\n",
       " \"        'id_str': '892420639486877696',\\n\",\n",
       " \"        'indices': [86, 109],\\n\",\n",
       " \"        'media_url': 'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\\n\",\n",
       " \"        'media_url_https': 'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\\n\",\n",
       " \"        'sizes': {'large': {'h': 528, 'resize': 'fit', 'w': 540},\\n\",\n",
       " \"         'medium': {'h': 528, 'resize': 'fit', 'w': 540},\\n\",\n",
       " \"         'small': {'h': 528, 'resize': 'fit', 'w': 540},\\n\",\n",
       " \"         'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\\n\",\n",
       " \"        'type': 'photo',\\n\",\n",
       " \"        'url': 'https://t.co/MgUWQ76dJU'}],\\n\",\n",
       " \"      'symbols': [],\\n\",\n",
       " \"      'urls': [],\\n\",\n",
       " \"      'user_mentions': []},\\n\",\n",
       " \"     'extended_entities': {'media': [{'display_url': 'pic.twitter.com/MgUWQ76dJU',\\n\",\n",
       " \"        'expanded_url': 'https://twitter.com/dog_rates/status/892420643555336193/photo/1',\\n\",\n",
       " \"        'id': 892420639486877696,\\n\",\n",
       " \"        'id_str': '892420639486877696',\\n\",\n",
       " \"        'indices': [86, 109],\\n\",\n",
       " \"        'media_url': 'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\\n\",\n",
       " \"        'media_url_https': 'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\\n\",\n",
       " \"        'sizes': {'large': {'h': 528, 'resize': 'fit', 'w': 540},\\n\",\n",
       " \"         'medium': {'h': 528, 'resize': 'fit', 'w': 540},\\n\",\n",
       " \"         'small': {'h': 528, 'resize': 'fit', 'w': 540},\\n\",\n",
       " \"         'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\\n\",\n",
       " \"        'type': 'photo',\\n\",\n",
       " \"        'url': 'https://t.co/MgUWQ76dJU'}]},\\n\",\n",
       " \"     'favorite_count': 38492,\\n\",\n",
       " \"     'favorited': False,\\n\",\n",
       " '     \\'full_text\\': \"This is Phineas. He\\'s a mystical boy. Only ever appears in the hole of a donut. 13/10 https://t.co/MgUWQ76dJU\",\\n',\n",
       " \"     'geo': None,\\n\",\n",
       " \"     'id': 892420643555336193,\\n\",\n",
       " \"     'id_str': '892420643555336193',\\n\",\n",
       " \"     'in_reply_to_screen_name': None,\\n\",\n",
       " \"     'in_reply_to_status_id': None,\\n\",\n",
       " \"     'in_reply_to_status_id_str': None,\\n\",\n",
       " \"     'in_reply_to_user_id': None,\\n\",\n",
       " \"     'in_reply_to_user_id_str': None,\\n\",\n",
       " \"     'is_quote_status': False,\\n\",\n",
       " \"     'lang': 'en',\\n\",\n",
       " \"     'place': None,\\n\",\n",
       " \"     'possibly_sensitive': False,\\n\",\n",
       " \"     'possibly_sensitive_appealable': False,\\n\",\n",
       " \"     'retweet_count': 8480,\\n\",\n",
       " \"     'retweeted': False,\\n\",\n",
       " '     \\'source\\': \\'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\\',\\n',\n",
       " \"     'truncated': False,\\n\",\n",
       " \"     'user': {'contributors_enabled': False,\\n\",\n",
       " \"      'created_at': 'Sun Nov 15 21:41:29 +0000 2015',\\n\",\n",
       " \"      'default_profile': False,\\n\",\n",
       " \"      'default_profile_image': False,\\n\",\n",
       " \"      'description': 'Your Only Source For Professional Dog Ratings  IG, FB, Snapchat â‡¨ WeRateDogs â\\xa0€â\\xa0€â\\xa0€â\\xa0€ Business Inquiries: dogratingtwitter@gmail.com',\\n\",\n",
       " \"      'entities': {'description': {'urls': []},\\n\",\n",
       " \"       'url': {'urls': [{'display_url': 'weratedogs.com',\\n\",\n",
       " \"          'expanded_url': 'http://weratedogs.com',\\n\",\n",
       " \"          'indices': [0, 23],\\n\",\n",
       " \"          'url': 'https://t.co/N7sNNHAEXS'}]}},\\n\",\n",
       " \"      'favourites_count': 137074,\\n\",\n",
       " \"      'follow_request_sent': False,\\n\",\n",
       " \"      'followers_count': 7174950,\\n\",\n",
       " \"      'following': False,\\n\",\n",
       " \"      'friends_count': 10,\\n\",\n",
       " \"      'geo_enabled': True,\\n\",\n",
       " \"      'has_extended_profile': False,\\n\",\n",
       " \"      'id': 4196983835,\\n\",\n",
       " \"      'id_str': '4196983835',\\n\",\n",
       " \"      'is_translation_enabled': False,\\n\",\n",
       " \"      'is_translator': False,\\n\",\n",
       " \"      'lang': 'en',\\n\",\n",
       " \"      'listed_count': 4906,\\n\",\n",
       " \"      'location': 'â‡© merch â‡©         DM YOUR DOGS',\\n\",\n",
       " \"      'name': 'WeRateDogsâ„¢',\\n\",\n",
       " \"      'notifications': False,\\n\",\n",
       " \"      'profile_background_color': '000000',\\n\",\n",
       " \"      'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\\n\",\n",
       " \"      'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\\n\",\n",
       " \"      'profile_background_tile': False,\\n\",\n",
       " \"      'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4196983835/1525830435',\\n\",\n",
       " \"      'profile_image_url': 'http://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg',\\n\",\n",
       " \"      'profile_image_url_https': 'https://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg',\\n\",\n",
       " \"      'profile_link_color': 'F5ABB5',\\n\",\n",
       " \"      'profile_sidebar_border_color': '000000',\\n\",\n",
       " \"      'profile_sidebar_fill_color': '000000',\\n\",\n",
       " \"      'profile_text_color': '000000',\\n\",\n",
       " \"      'profile_use_background_image': False,\\n\",\n",
       " \"      'protected': False,\\n\",\n",
       " \"      'screen_name': 'dog_rates',\\n\",\n",
       " \"      'statuses_count': 8670,\\n\",\n",
       " \"      'time_zone': None,\\n\",\n",
       " \"      'translator_type': 'none',\\n\",\n",
       " \"      'url': 'https://t.co/N7sNNHAEXS',\\n\",\n",
       " \"      'utc_offset': None,\\n\",\n",
       " \"      'verified': True}}\\n\",\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# Extract elements\\n',\n",
       " \"print(tmp['id'])\\n\",\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '    892420643555336193\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# Extract elements from the lines list\\n',\n",
       " '\\n',\n",
       " '# total number of tweets \\n',\n",
       " 'number_of_tweets=len(lines)\\n',\n",
       " '\\n',\n",
       " '# initialize a set of lists that will hold informative tweet elements \\n',\n",
       " 'list_t_ids=[] # will store ids\\n',\n",
       " 'list_t_created_at=[] # will store the dates tweets were created \\n',\n",
       " 'list_t_full_text=[] # will store the full text\\n',\n",
       " 'list_t_favorite_count=[] # will store the count of favorites\\n',\n",
       " 'list_t_retweet_count=[] # will store the count of retweets\\n',\n",
       " '\\n',\n",
       " '# iterate over the lines list of tweets, extract information and save to the initialized lists\\n',\n",
       " 'for i in range(number_of_tweets):\\n',\n",
       " '    \\n',\n",
       " '    # load a list element containing a tweet into json format\\n',\n",
       " '    tmp = json.loads(lines[i])\\n',\n",
       " '    \\n',\n",
       " '    # extract and add the id\\n',\n",
       " \"    list_t_ids.append(tmp['id'])\\n\",\n",
       " '\\n',\n",
       " '    # extract and add the date the tweet was created\\n',\n",
       " \"    list_t_created_at.append(tmp['created_at'])\\n\",\n",
       " '\\n',\n",
       " '    \\n',\n",
       " '    # extract and add the full text from the tweet\\n',\n",
       " \"    list_t_full_text.append(tmp['full_text'])\\n\",\n",
       " '    \\n',\n",
       " '    # extract add the favorite count\\n',\n",
       " \"    list_t_favorite_count.append(tmp['favorite_count'])\\n\",\n",
       " '    \\n',\n",
       " '    # extract and add the retweet count\\n',\n",
       " \"    list_t_retweet_count.append(tmp['retweet_count'])\\n\",\n",
       " '        \\n',\n",
       " '    #print(i)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# concatenate the lists into a pandas dataframe\\n',\n",
       " 'lists = [list_t_ids, list_t_created_at, list_t_full_text,list_t_favorite_count,list_t_retweet_count]\\n',\n",
       " 'df_json_tweets = pd.concat([pd.Series(x) for x in lists], axis=1)\\n',\n",
       " \"df_json_tweets.columns = ['tweet_id', 'time_created','full_text','favorite_count','retweet_count']\\n\",\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# examine the jason_tweets dataframe\\n',\n",
       " 'df_json_tweets.head()\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '<div>\\n',\n",
       " '<style scoped>\\n',\n",
       " '    .dataframe tbody tr th:only-of-type {\\n',\n",
       " '        vertical-align: middle;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe tbody tr th {\\n',\n",
       " '        vertical-align: top;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe thead th {\\n',\n",
       " '        text-align: right;\\n',\n",
       " '    }\\n',\n",
       " '</style>\\n',\n",
       " '<table border=\"1\" class=\"dataframe\">\\n',\n",
       " '  <thead>\\n',\n",
       " '    <tr style=\"text-align: right;\">\\n',\n",
       " '      <th></th>\\n',\n",
       " '      <th>tweet_id</th>\\n',\n",
       " '      <th>time_created</th>\\n',\n",
       " '      <th>full_text</th>\\n',\n",
       " '      <th>favorite_count</th>\\n',\n",
       " '      <th>retweet_count</th>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </thead>\\n',\n",
       " '  <tbody>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>0</th>\\n',\n",
       " '      <td>892420643555336193</td>\\n',\n",
       " '      <td>Tue Aug 01 16:23:56 +0000 2017</td>\\n',\n",
       " \"      <td>This is Phineas. He's a mystical boy. Only eve...</td>\\n\",\n",
       " '      <td>38492</td>\\n',\n",
       " '      <td>8480</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>1</th>\\n',\n",
       " '      <td>892177421306343426</td>\\n',\n",
       " '      <td>Tue Aug 01 00:17:27 +0000 2017</td>\\n',\n",
       " \"      <td>This is Tilly. She's just checking pup on you....</td>\\n\",\n",
       " '      <td>32986</td>\\n',\n",
       " '      <td>6241</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>2</th>\\n',\n",
       " '      <td>891815181378084864</td>\\n',\n",
       " '      <td>Mon Jul 31 00:18:03 +0000 2017</td>\\n',\n",
       " '      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\\n',\n",
       " '      <td>24840</td>\\n',\n",
       " '      <td>4137</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>3</th>\\n',\n",
       " '      <td>891689557279858688</td>\\n',\n",
       " '      <td>Sun Jul 30 15:58:51 +0000 2017</td>\\n',\n",
       " '      <td>This is Darla. She commenced a snooze mid meal...</td>\\n',\n",
       " '      <td>41865</td>\\n',\n",
       " '      <td>8598</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>4</th>\\n',\n",
       " '      <td>891327558926688256</td>\\n',\n",
       " '      <td>Sat Jul 29 16:00:24 +0000 2017</td>\\n',\n",
       " '      <td>This is Franklin. He would like you to stop ca...</td>\\n',\n",
       " '      <td>40029</td>\\n',\n",
       " '      <td>9336</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </tbody>\\n',\n",
       " '</table>\\n',\n",
       " '</div>\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# examine the json_tweets data structure\\n',\n",
       " 'df_json_tweets.info()\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " \"    <class 'pandas.core.frame.DataFrame'>\\n\",\n",
       " '    RangeIndex: 2342 entries, 0 to 2341\\n',\n",
       " '    Data columns (total 5 columns):\\n',\n",
       " '    tweet_id          2342 non-null int64\\n',\n",
       " '    time_created      2342 non-null object\\n',\n",
       " '    full_text         2342 non-null object\\n',\n",
       " '    favorite_count    2342 non-null int64\\n',\n",
       " '    retweet_count     2342 non-null int64\\n',\n",
       " '    dtypes: int64(3), object(2)\\n',\n",
       " '    memory usage: 91.6+ KB\\n',\n",
       " '    \\n',\n",
       " '\\n',\n",
       " '## Observation\\n',\n",
       " '\\n',\n",
       " 'df_json_tweets dataframe has 5 variables and 2343 observations. It has no missing values.\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " \"<a id='B'></a>\\n\",\n",
       " '[Top](#Top)\\n',\n",
       " '## B. Data Access Issues \\n',\n",
       " '(The insights here are summarized from analysis in this subsection.)\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '## Content Issues \\n',\n",
       " '\\n',\n",
       " '(Visual & Programmatically - completness, validity, accuracy, consistency)\\n',\n",
       " '\\n',\n",
       " '### twitter_archive dataframe\\n',\n",
       " '    \\n',\n",
       " '    - The expanded_url column, has some instances where the url is repeated multiple times in a cell separated by a comma\\n',\n",
       " '    - The name column has non name strings such as None, a, an \\n',\n",
       " '    - Rating_denominator as high as 80\\n',\n",
       " '    - The following variables should be integers instead of floats: in_reply_to_status_id,in_reply_to_user_id,    \\n',\n",
       " '      retweeted_status_id,retweeted_status_user_id \\n',\n",
       " '    - Contains retweets\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '### image_predictions dataframe\\n',\n",
       " '\\n',\n",
       " '    - p1, p2,p3: upper and lower case mixed together\\n',\n",
       " '    - p1, p2,p3: dash and underscore mixed in string eg. black-and-tan_coonhound\\t\\n',\n",
       " '    - Missing values when compared to twitter_archive dataframe\\n',\n",
       " '\\n',\n",
       " '###  tweet_json dataframe\\n',\n",
       " '\\n',\n",
       " '    - time_created should be a data/time object\\n',\n",
       " '\\n',\n",
       " '## Structural Issues\\n',\n",
       " '\\n',\n",
       " '(Visual & Programmatically -  variable(column), observation(row), unit(table))\\n',\n",
       " '\\n',\n",
       " '### twitter_archive dataframe\\n',\n",
       " '\\n',\n",
       " '    - The timestamp column contains two separate variables date and time. \\n',\n",
       " '    - The anchor text in source column is repeated numerous times\\n',\n",
       " \"    - Variables called 'doggo', 'floofer', 'pupper', 'puppo' are different growth stages of a pet based on age.\\n\",\n",
       " '\\n',\n",
       " '### image_predictions dataframe\\n',\n",
       " '\\n',\n",
       " '    - Merge the dataset with twitter_archive dataframe based on tweet_id\\n',\n",
       " '\\n',\n",
       " '###  tweet_json dataframe\\n',\n",
       " '\\n',\n",
       " '    - time_created could be further split into day, month and time \\n',\n",
       " '    - Merge this dataframe with twitter_archive dataframe\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " '# function to find duplicates in a dataframe column\\n',\n",
       " '# source:  https://stackoverflow.com/questions/15247628/how-to-find-duplicate-names-using-pandas\\n',\n",
       " 'def find_duplicates(df_column):\\n',\n",
       " '    names=df_column.value_counts()\\n',\n",
       " '    return(names[names>1])\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '# Analysing the twitter_archive dataframe\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " 'df_twitter_archive.head(2)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '<div>\\n',\n",
       " '<style scoped>\\n',\n",
       " '    .dataframe tbody tr th:only-of-type {\\n',\n",
       " '        vertical-align: middle;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe tbody tr th {\\n',\n",
       " '        vertical-align: top;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe thead th {\\n',\n",
       " '        text-align: right;\\n',\n",
       " '    }\\n',\n",
       " '</style>\\n',\n",
       " '<table border=\"1\" class=\"dataframe\">\\n',\n",
       " '  <thead>\\n',\n",
       " '    <tr style=\"text-align: right;\">\\n',\n",
       " '      <th></th>\\n',\n",
       " '      <th>tweet_id</th>\\n',\n",
       " '      <th>in_reply_to_status_id</th>\\n',\n",
       " '      <th>in_reply_to_user_id</th>\\n',\n",
       " '      <th>timestamp</th>\\n',\n",
       " '      <th>source</th>\\n',\n",
       " '      <th>text</th>\\n',\n",
       " '      <th>retweeted_status_id</th>\\n',\n",
       " '      <th>retweeted_status_user_id</th>\\n',\n",
       " '      <th>retweeted_status_timestamp</th>\\n',\n",
       " '      <th>expanded_urls</th>\\n',\n",
       " '      <th>rating_numerator</th>\\n',\n",
       " '      <th>rating_denominator</th>\\n',\n",
       " '      <th>name</th>\\n',\n",
       " '      <th>doggo</th>\\n',\n",
       " '      <th>floofer</th>\\n',\n",
       " '      <th>pupper</th>\\n',\n",
       " '      <th>puppo</th>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </thead>\\n',\n",
       " '  <tbody>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>0</th>\\n',\n",
       " '      <td>892420643555336193</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>2017-08-01 16:23:56 +0000</td>\\n',\n",
       " '      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n',\n",
       " \"      <td>This is Phineas. He's a mystical boy. Only eve...</td>\\n\",\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n',\n",
       " '      <td>13</td>\\n',\n",
       " '      <td>10</td>\\n',\n",
       " '      <td>Phineas</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '    <tr>\\n',\n",
       " '      <th>1</th>\\n',\n",
       " '      <td>892177421306343426</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>2017-08-01 00:17:27 +0000</td>\\n',\n",
       " '      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n',\n",
       " \"      <td>This is Tilly. She's just checking pup on you....</td>\\n\",\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>NaN</td>\\n',\n",
       " '      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n',\n",
       " '      <td>13</td>\\n',\n",
       " '      <td>10</td>\\n',\n",
       " '      <td>Tilly</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '      <td>None</td>\\n',\n",
       " '    </tr>\\n',\n",
       " '  </tbody>\\n',\n",
       " '</table>\\n',\n",
       " '</div>\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'There is presence of missing values in twitter archive table so this needs to be further investigated. The timestamp column contains two separate variables date and time. \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " 'df_twitter_archive.columns\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " \"    Index(['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp',\\n\",\n",
       " \"           'source', 'text', 'retweeted_status_id', 'retweeted_status_user_id',\\n\",\n",
       " \"           'retweeted_status_timestamp', 'expanded_urls', 'rating_numerator',\\n\",\n",
       " \"           'rating_denominator', 'name', 'doggo', 'floofer', 'pupper', 'puppo'],\\n\",\n",
       " \"          dtype='object')\\n\",\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " \"Variables called 'doggo', 'floofer', 'pupper', 'puppo' are different growth stages of a pet and should be in one column.\\n\",\n",
       " '\\n',\n",
       " '\\n',\n",
       " '```python\\n',\n",
       " 'df_twitter_archive.sample(5)\\n',\n",
       " '```\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '<div>\\n',\n",
       " '<style scoped>\\n',\n",
       " '    .dataframe tbody tr th:only-of-type {\\n',\n",
       " '        vertical-align: middle;\\n',\n",
       " '    }\\n',\n",
       " '\\n',\n",
       " '    .dataframe tbody tr th {\\n',\n",
       " '        vertical-align: top;\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the file with read only permit\n",
    "f = open(markdown_name, \"r\")\n",
    "# use readlines to read all lines in the file\n",
    "# The variable \"lines\" is a list containing all lines in the file\n",
    "lines = f.readlines()\n",
    "# close the file after reading the lines.\n",
    "f.close()\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the all the element sin lines list witn @@@ at the end of each line to perform operations\n",
    "content_joined=\"@@@\".join(lines)\n",
    "\n",
    "#use this below to split at @@@ and then save it to a md file\n",
    "#content_joined.split('@@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@@@# Wrangle Report\\n@@@\\n@@@   \\n@@@**Table of Contents**<a id=\\'Top\\'><a>   \\n@@@[Reference](#Reference)  \\n@@@[A. Data Gathering Efforts](#A)  \\n@@@[B. Data Access Issues](#B)  \\n@@@[C. Data Cleaning](#C)\\n@@@\\n@@@\\n@@@\\n@@@<a id=\\'Reference\\'></a>\\n@@@[Top](#Top)\\n@@@# Reference \\n@@@\\n@@@\\n@@@https://stackoverflow.com/questions/32400867/pandas-read-csv-from-url  \\n@@@https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object3\\n@@@https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file\\n@@@https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file\\n@@@https://stackoverflow.com/questions/41001973/python-3-5-1-nameerror-name-json-is-not-defined\\n@@@https://stackoverflow.com/questions/27900451/convert-tweepy-status-object-into-json\\n@@@https://gist.github.com/yanofsky/5436496\\n@@@https://stackoverflow.com/questions/11716380/python-beautifulsoup-extract-text-from-anchor-tag\\n@@@https://stackoverflow.com/questions/30522724/take-multiple-lists-into-dataframe\\n@@@https://stackoverflow.com/questions/15247628/how-to-find-duplicate-names-using-pandas  \\n@@@https://stackoverflow.com/questions/466345/converting-string-into-datetime\\n@@@https://stackoverflow.com/questions/33034559/how-to-remove-last-the-two-digits-in-a-column-that-is-of-integer-type\\n@@@https://stackoverflow.com/questions/25146121/extracting-just-month-and-year-from-pandas-datetime-column-python\\n@@@https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict\\n@@@https://stackoverflow.com/questions/39092067/pandas-dataframe-convert-column-type-to-string-or-categorical\\n@@@https://stackoverflow.com/questions/18792918/combine-two-pandas-data-frames-join-on-a-common-column\\n@@@\\n@@@\\n@@@```python\\n@@@#import libraries\\n@@@import requests # reading files programmatically\\n@@@import os # manipulating file paths\\n@@@import pandas as pd\\n@@@import numpy as np\\n@@@import tweepy #read tweeter data -- pip install tweepy\\n@@@#import simplejson as json # to make json dumps --  pip install simplejson\\n@@@import json # to create json objects \\n@@@import time # to calculate the execution times of functions\\n@@@from datetime import datetime\\n@@@\\n@@@# set seed for sampling\\n@@@np.random.seed(27)\\n@@@\\n@@@```\\n@@@\\n@@@<a id=\\'A\\'></a>\\n@@@[Top](#Top)\\n@@@# A. Data Gathering Efforts \\n@@@\\n@@@## 1. Downloading the twitter-archive-enhanced.csv\\n@@@\\n@@@The twitter-archive-enhanced.csv was saved to the local directory by clicking the following link https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv \\n@@@and saving the corresponding csv file in the local working directory. \\n@@@\\n@@@\\n@@@```python\\n@@@# read the twitter-archive-enhanced.csv file intp a pandas dataframe\\n@@@df_twitter_archive=pd.read_csv(\\'twitter-archive-enhanced.csv\\')\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the dataframe\\n@@@df_twitter_archive.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 16:23:56 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 00:17:27 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the dataframe structure\\n@@@df_twitter_archive.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2356 entries, 0 to 2355\\n@@@    Data columns (total 17 columns):\\n@@@    tweet_id                      2356 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2356 non-null object\\n@@@    source                        2356 non-null object\\n@@@    text                          2356 non-null object\\n@@@    retweeted_status_id           181 non-null float64\\n@@@    retweeted_status_user_id      181 non-null float64\\n@@@    retweeted_status_timestamp    181 non-null object\\n@@@    expanded_urls                 2297 non-null object\\n@@@    rating_numerator              2356 non-null int64\\n@@@    rating_denominator            2356 non-null int64\\n@@@    name                          2356 non-null object\\n@@@    doggo                         2356 non-null object\\n@@@    floofer                       2356 non-null object\\n@@@    pupper                        2356 non-null object\\n@@@    puppo                         2356 non-null object\\n@@@    dtypes: float64(4), int64(3), object(10)\\n@@@    memory usage: 313.0+ KB\\n@@@    \\n@@@\\n@@@## Observation\\n@@@The df_twitter_archive dataframe has 17 variables and 2356 observations. Some of the variables have missing values.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@## 2. Downloading programmatically the image_predictions.tsv file\\n@@@\\n@@@The image_predictions.tsv was programmatically downloaded from https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv using the requests funciton.\\n@@@\\n@@@\\n@@@```python\\n@@@# programmatically download the image_predictions.tsv file\\n@@@url=\\'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\\'\\n@@@response=requests.get(url) # saves the file in the memory\\n@@@\\n@@@# view the file in the memory\\n@@@# response.content\\n@@@\\n@@@# create the file name by truncating the file name from the end of the url\\n@@@file_name=url.split(\\'/\\')[-1] #\\'image-predictions.tsv\\'\\n@@@\\n@@@# write the tsv file to the working directory \\n@@@with open(file_name, mode=\\'wb\\') as file:\\n@@@    file.write(response.content)\\n@@@    \\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# read the image-predictions.tsv file into a pandas file\\n@@@df_image_predictions=pd.read_csv(\\'image-predictions.tsv\\', sep = \\'\\\\t\\', encoding = \\'utf-8\\')\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the image_predictions_df dataframe\\n@@@df_image_predictions.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>img_num</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>666020888022790149</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Welsh_springer_spaniel</td>\\n@@@      <td>0.465074</td>\\n@@@      <td>True</td>\\n@@@      <td>collie</td>\\n@@@      <td>0.156665</td>\\n@@@      <td>True</td>\\n@@@      <td>Shetland_sheepdog</td>\\n@@@      <td>0.061428</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>666029285002620928</td>\\n@@@      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.506826</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.074192</td>\\n@@@      <td>True</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.072010</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the structure of the df_image_predictions dataframe\\n@@@df_image_predictions.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2075 entries, 0 to 2074\\n@@@    Data columns (total 12 columns):\\n@@@    tweet_id    2075 non-null int64\\n@@@    jpg_url     2075 non-null object\\n@@@    img_num     2075 non-null int64\\n@@@    p1          2075 non-null object\\n@@@    p1_conf     2075 non-null float64\\n@@@    p1_dog      2075 non-null bool\\n@@@    p2          2075 non-null object\\n@@@    p2_conf     2075 non-null float64\\n@@@    p2_dog      2075 non-null bool\\n@@@    p3          2075 non-null object\\n@@@    p3_conf     2075 non-null float64\\n@@@    p3_dog      2075 non-null bool\\n@@@    dtypes: bool(3), float64(3), int64(2), object(4)\\n@@@    memory usage: 152.1+ KB\\n@@@    \\n@@@\\n@@@## Observation\\n@@@\\n@@@The df_image_predictions has 12 variables and 2075 observations. The are no missing values in the dataframe.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@## 3. Downloading Twitter data via Twitter API and tweepy library\\n@@@\\n@@@\\n@@@```python\\n@@@## set tweet consumer and access key >>> replace the ### with actual keys\\n@@@consumer_key = \\'Yn71UCiC2MdIHkBalOBc08yMO\\'\\n@@@consumer_secret = \\'K7CAtE6njCkEA3trt592jJEBDRa0a6OkZsoV6MsdkM8BLWPSCl\\'\\n@@@access_token = \\'108732090-QR9V8gfQGTPu6tJBzNkINGhKjCTMh0vhuOziyoe3\\'\\n@@@access_secret = \\'HsALvm8Y5qG77fTMrfGeWjVYZY6DnupdoZu4FSBnaUmk2\\'\\n@@@\\n@@@auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\\n@@@auth.set_access_token(access_token, access_secret)\\n@@@\\n@@@# use jsonparser to make json readable content, create json dumps and query json objects\\n@@@# wait_on_rate_limit = True , allows the program to wait during timeouts \\n@@@# wait_on_rate_limit_notify = True, writes to screen when waiting\\n@@@api = tweepy.API(auth,parser=tweepy.parsers.JSONParser(),wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# function to append file line by line\\n@@@# The function was adapted from https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file\\n@@@# input: the function takes a filename string and text\\n@@@# process: the function opens a file and adds the text in append mode\\n@@@# out: none\\n@@@def FileSave(filename,content):\\n@@@    with open(filename, \"a\") as myfile:\\n@@@        myfile.write(content)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# input: the function takes a list of tweet ids and a filename\\n@@@# process: the function downloads tweets corresponding to a tweet ids and adds it to a file\\n@@@# out: the function prints out the time taken to download the tweets, prints the error msgs and\\n@@@#      returns a list of ids that could not be downloaded\\n@@@\\n@@@def download_tweets(id_list,filename):\\n@@@    \\n@@@    # set the start time\\n@@@    start_time = time.time()\\n@@@\\n@@@    unloaded_tweet_ids=[]\\n@@@    counter=0\\n@@@    for i in id_list:\\n@@@        try:\\n@@@            #print(counter,\\' >> Tweet id: \\',i)\\n@@@            tweet=api.get_status(i,tweet_mode=\\'extended\\')\\n@@@            FileSave(filename,json.dumps(tweet)+\\'\\\\n\\')\\n@@@            counter=counter+1\\n@@@            \\n@@@        except Exception as download_error_msg:\\n@@@            print(counter,\\' >> Tweet id: \\',i)\\n@@@            print(download_error_msg)\\n@@@            unloaded_tweet_ids.append(i)\\n@@@            counter=counter+1\\n@@@\\n@@@            \\n@@@    #print unloaded tweeter ids\\n@@@    print(\\'\\\\n \\\\nTotal number of Tweeter ids :\\',len(id_list))\\n@@@    print(\\'The following \\',len(unloaded_tweet_ids), \\'tweet ids could not be downloaded for various reasons: \\')\\n@@@    print(unloaded_tweet_ids)\\n@@@    \\n@@@    # set the end time\\n@@@    end_time = time.time()\\n@@@\\n@@@    # print the execution time\\n@@@    print(\\'\\\\n \\\\nThe download process took: \\', (end_time - start_time)/60, \\' minutes\\')\\n@@@    \\n@@@    return(unloaded_tweet_ids)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# set the tweet ids that will be using in the api to access the actual data\\n@@@tweet_id=df_twitter_archive[\\'tweet_id\\']\\n@@@\\n@@@# download tweets by passing the tweet_id list and tweet_json.txt filename\\n@@@# save the results of unloaded ids so they can be attempted again\\n@@@error_ids_01=download_tweets(tweet_id,\\'tweet_json.txt\\')\\n@@@```\\n@@@\\n@@@    19  >> Tweet id:  888202515573088257\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    95  >> Tweet id:  873697596434513921\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    118  >> Tweet id:  869988702071779329\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    132  >> Tweet id:  866816280283807744\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    155  >> Tweet id:  861769973181624320\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    247  >> Tweet id:  845459076796616705\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    260  >> Tweet id:  842892208864923648\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    298  >> Tweet id:  837012587749474308\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    382  >> Tweet id:  827228250799742977\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    566  >> Tweet id:  802247111496568832\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    784  >> Tweet id:  775096608509886464\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    815  >> Tweet id:  771004394259247104\\n@@@    [{\\'code\\': 179, \\'message\\': \\'Sorry, you are not authorized to see this status.\\'}]\\n@@@    818  >> Tweet id:  770743923962707968\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    \\n@@@\\n@@@    Rate limit reached. Sleeping for: 732\\n@@@    \\n@@@\\n@@@    932  >> Tweet id:  754011816964026368\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    \\n@@@\\n@@@    Rate limit reached. Sleeping for: 728\\n@@@    \\n@@@\\n@@@    \\n@@@     \\n@@@    Total number of Tweeter ids : 2356\\n@@@    The following  14 tweet ids could not be downloaded for various reasons: \\n@@@    [888202515573088257, 873697596434513921, 869988702071779329, 866816280283807744, 861769973181624320, 845459076796616705, 842892208864923648, 837012587749474308, 827228250799742977, 802247111496568832, 775096608509886464, 771004394259247104, 770743923962707968, 754011816964026368]\\n@@@    \\n@@@     \\n@@@    The download process took:  31.737418989340465  minutes\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# try to download the tweet contents corresponding the error tweets\\n@@@error_ids_02=download_tweets(error_ids_01,\\'tweet_json.txt\\')\\n@@@```\\n@@@\\n@@@    0  >> Tweet id:  888202515573088257\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    1  >> Tweet id:  873697596434513921\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    2  >> Tweet id:  869988702071779329\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    3  >> Tweet id:  866816280283807744\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    4  >> Tweet id:  861769973181624320\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    5  >> Tweet id:  845459076796616705\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    6  >> Tweet id:  842892208864923648\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    7  >> Tweet id:  837012587749474308\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    8  >> Tweet id:  827228250799742977\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    9  >> Tweet id:  802247111496568832\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    10  >> Tweet id:  775096608509886464\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    11  >> Tweet id:  771004394259247104\\n@@@    [{\\'code\\': 179, \\'message\\': \\'Sorry, you are not authorized to see this status.\\'}]\\n@@@    12  >> Tweet id:  770743923962707968\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    13  >> Tweet id:  754011816964026368\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    \\n@@@     \\n@@@    Total number of Tweeter ids : 14\\n@@@    The following  14 tweet ids could not be downloaded for various reasons: \\n@@@    [888202515573088257, 873697596434513921, 869988702071779329, 866816280283807744, 861769973181624320, 845459076796616705, 842892208864923648, 837012587749474308, 827228250799742977, 802247111496568832, 775096608509886464, 771004394259247104, 770743923962707968, 754011816964026368]\\n@@@    \\n@@@     \\n@@@    The download process took:  0.03408433596293132  minutes\\n@@@    \\n@@@\\n@@@## Observation\\n@@@\\n@@@At this point, we have successfully saved each tweet\\'s entire content in a tweet_json.txt file with each tweet in a new line.There were 13 tweets that could not be downloaded for various reasons.  \\n@@@\\n@@@Next, we will read the file into memory where each tweet will be saved into a separate element in a list called \\'lines\\'. We will then iterate through the lines list and extract interesting elements such as tweet text, favourites count, retweet count etc in separate lists and later concatenate the lists into a dataframe.  \\n@@@\\n@@@\\n@@@```python\\n@@@## read json file to a list array and strip new line charactor\\n@@@lines = [line.rstrip(\\'\\\\n\\') for line in open(\\'tweet_json.txt\\')]\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# read one tweet into a temp file to examine its content\\n@@@# load the tweet into a json format for easier extraction of information\\n@@@tmp = json.loads(lines[0])\\n@@@\\n@@@# examine a tweet\\n@@@tmp\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    {\\'contributors\\': None,\\n@@@     \\'coordinates\\': None,\\n@@@     \\'created_at\\': \\'Tue Aug 01 16:23:56 +0000 2017\\',\\n@@@     \\'display_text_range\\': [0, 85],\\n@@@     \\'entities\\': {\\'hashtags\\': [],\\n@@@      \\'media\\': [{\\'display_url\\': \\'pic.twitter.com/MgUWQ76dJU\\',\\n@@@        \\'expanded_url\\': \\'https://twitter.com/dog_rates/status/892420643555336193/photo/1\\',\\n@@@        \\'id\\': 892420639486877696,\\n@@@        \\'id_str\\': \\'892420639486877696\\',\\n@@@        \\'indices\\': [86, 109],\\n@@@        \\'media_url\\': \\'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'media_url_https\\': \\'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'sizes\\': {\\'large\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'medium\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'small\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'thumb\\': {\\'h\\': 150, \\'resize\\': \\'crop\\', \\'w\\': 150}},\\n@@@        \\'type\\': \\'photo\\',\\n@@@        \\'url\\': \\'https://t.co/MgUWQ76dJU\\'}],\\n@@@      \\'symbols\\': [],\\n@@@      \\'urls\\': [],\\n@@@      \\'user_mentions\\': []},\\n@@@     \\'extended_entities\\': {\\'media\\': [{\\'display_url\\': \\'pic.twitter.com/MgUWQ76dJU\\',\\n@@@        \\'expanded_url\\': \\'https://twitter.com/dog_rates/status/892420643555336193/photo/1\\',\\n@@@        \\'id\\': 892420639486877696,\\n@@@        \\'id_str\\': \\'892420639486877696\\',\\n@@@        \\'indices\\': [86, 109],\\n@@@        \\'media_url\\': \\'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'media_url_https\\': \\'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'sizes\\': {\\'large\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'medium\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'small\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'thumb\\': {\\'h\\': 150, \\'resize\\': \\'crop\\', \\'w\\': 150}},\\n@@@        \\'type\\': \\'photo\\',\\n@@@        \\'url\\': \\'https://t.co/MgUWQ76dJU\\'}]},\\n@@@     \\'favorite_count\\': 38492,\\n@@@     \\'favorited\\': False,\\n@@@     \\'full_text\\': \"This is Phineas. He\\'s a mystical boy. Only ever appears in the hole of a donut. 13/10 https://t.co/MgUWQ76dJU\",\\n@@@     \\'geo\\': None,\\n@@@     \\'id\\': 892420643555336193,\\n@@@     \\'id_str\\': \\'892420643555336193\\',\\n@@@     \\'in_reply_to_screen_name\\': None,\\n@@@     \\'in_reply_to_status_id\\': None,\\n@@@     \\'in_reply_to_status_id_str\\': None,\\n@@@     \\'in_reply_to_user_id\\': None,\\n@@@     \\'in_reply_to_user_id_str\\': None,\\n@@@     \\'is_quote_status\\': False,\\n@@@     \\'lang\\': \\'en\\',\\n@@@     \\'place\\': None,\\n@@@     \\'possibly_sensitive\\': False,\\n@@@     \\'possibly_sensitive_appealable\\': False,\\n@@@     \\'retweet_count\\': 8480,\\n@@@     \\'retweeted\\': False,\\n@@@     \\'source\\': \\'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\\',\\n@@@     \\'truncated\\': False,\\n@@@     \\'user\\': {\\'contributors_enabled\\': False,\\n@@@      \\'created_at\\': \\'Sun Nov 15 21:41:29 +0000 2015\\',\\n@@@      \\'default_profile\\': False,\\n@@@      \\'default_profile_image\\': False,\\n@@@      \\'description\\': \\'Your Only Source For Professional Dog Ratings  IG, FB, Snapchat â‡¨ WeRateDogs â\\xa0€â\\xa0€â\\xa0€â\\xa0€ Business Inquiries: dogratingtwitter@gmail.com\\',\\n@@@      \\'entities\\': {\\'description\\': {\\'urls\\': []},\\n@@@       \\'url\\': {\\'urls\\': [{\\'display_url\\': \\'weratedogs.com\\',\\n@@@          \\'expanded_url\\': \\'http://weratedogs.com\\',\\n@@@          \\'indices\\': [0, 23],\\n@@@          \\'url\\': \\'https://t.co/N7sNNHAEXS\\'}]}},\\n@@@      \\'favourites_count\\': 137074,\\n@@@      \\'follow_request_sent\\': False,\\n@@@      \\'followers_count\\': 7174950,\\n@@@      \\'following\\': False,\\n@@@      \\'friends_count\\': 10,\\n@@@      \\'geo_enabled\\': True,\\n@@@      \\'has_extended_profile\\': False,\\n@@@      \\'id\\': 4196983835,\\n@@@      \\'id_str\\': \\'4196983835\\',\\n@@@      \\'is_translation_enabled\\': False,\\n@@@      \\'is_translator\\': False,\\n@@@      \\'lang\\': \\'en\\',\\n@@@      \\'listed_count\\': 4906,\\n@@@      \\'location\\': \\'â‡© merch â‡©         DM YOUR DOGS\\',\\n@@@      \\'name\\': \\'WeRateDogsâ„¢\\',\\n@@@      \\'notifications\\': False,\\n@@@      \\'profile_background_color\\': \\'000000\\',\\n@@@      \\'profile_background_image_url\\': \\'http://abs.twimg.com/images/themes/theme1/bg.png\\',\\n@@@      \\'profile_background_image_url_https\\': \\'https://abs.twimg.com/images/themes/theme1/bg.png\\',\\n@@@      \\'profile_background_tile\\': False,\\n@@@      \\'profile_banner_url\\': \\'https://pbs.twimg.com/profile_banners/4196983835/1525830435\\',\\n@@@      \\'profile_image_url\\': \\'http://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg\\',\\n@@@      \\'profile_image_url_https\\': \\'https://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg\\',\\n@@@      \\'profile_link_color\\': \\'F5ABB5\\',\\n@@@      \\'profile_sidebar_border_color\\': \\'000000\\',\\n@@@      \\'profile_sidebar_fill_color\\': \\'000000\\',\\n@@@      \\'profile_text_color\\': \\'000000\\',\\n@@@      \\'profile_use_background_image\\': False,\\n@@@      \\'protected\\': False,\\n@@@      \\'screen_name\\': \\'dog_rates\\',\\n@@@      \\'statuses_count\\': 8670,\\n@@@      \\'time_zone\\': None,\\n@@@      \\'translator_type\\': \\'none\\',\\n@@@      \\'url\\': \\'https://t.co/N7sNNHAEXS\\',\\n@@@      \\'utc_offset\\': None,\\n@@@      \\'verified\\': True}}\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# Extract elements\\n@@@print(tmp[\\'id\\'])\\n@@@```\\n@@@\\n@@@    892420643555336193\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# Extract elements from the lines list\\n@@@\\n@@@# total number of tweets \\n@@@number_of_tweets=len(lines)\\n@@@\\n@@@# initialize a set of lists that will hold informative tweet elements \\n@@@list_t_ids=[] # will store ids\\n@@@list_t_created_at=[] # will store the dates tweets were created \\n@@@list_t_full_text=[] # will store the full text\\n@@@list_t_favorite_count=[] # will store the count of favorites\\n@@@list_t_retweet_count=[] # will store the count of retweets\\n@@@\\n@@@# iterate over the lines list of tweets, extract information and save to the initialized lists\\n@@@for i in range(number_of_tweets):\\n@@@    \\n@@@    # load a list element containing a tweet into json format\\n@@@    tmp = json.loads(lines[i])\\n@@@    \\n@@@    # extract and add the id\\n@@@    list_t_ids.append(tmp[\\'id\\'])\\n@@@\\n@@@    # extract and add the date the tweet was created\\n@@@    list_t_created_at.append(tmp[\\'created_at\\'])\\n@@@\\n@@@    \\n@@@    # extract and add the full text from the tweet\\n@@@    list_t_full_text.append(tmp[\\'full_text\\'])\\n@@@    \\n@@@    # extract add the favorite count\\n@@@    list_t_favorite_count.append(tmp[\\'favorite_count\\'])\\n@@@    \\n@@@    # extract and add the retweet count\\n@@@    list_t_retweet_count.append(tmp[\\'retweet_count\\'])\\n@@@        \\n@@@    #print(i)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# concatenate the lists into a pandas dataframe\\n@@@lists = [list_t_ids, list_t_created_at, list_t_full_text,list_t_favorite_count,list_t_retweet_count]\\n@@@df_json_tweets = pd.concat([pd.Series(x) for x in lists], axis=1)\\n@@@df_json_tweets.columns = [\\'tweet_id\\', \\'time_created\\',\\'full_text\\',\\'favorite_count\\',\\'retweet_count\\']\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the jason_tweets dataframe\\n@@@df_json_tweets.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>time_created</th>\\n@@@      <th>full_text</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>Tue Aug 01 16:23:56 +0000 2017</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>38492</td>\\n@@@      <td>8480</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>Tue Aug 01 00:17:27 +0000 2017</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>32986</td>\\n@@@      <td>6241</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>Mon Jul 31 00:18:03 +0000 2017</td>\\n@@@      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\\n@@@      <td>24840</td>\\n@@@      <td>4137</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>Sun Jul 30 15:58:51 +0000 2017</td>\\n@@@      <td>This is Darla. She commenced a snooze mid meal...</td>\\n@@@      <td>41865</td>\\n@@@      <td>8598</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>Sat Jul 29 16:00:24 +0000 2017</td>\\n@@@      <td>This is Franklin. He would like you to stop ca...</td>\\n@@@      <td>40029</td>\\n@@@      <td>9336</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the json_tweets data structure\\n@@@df_json_tweets.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2342 entries, 0 to 2341\\n@@@    Data columns (total 5 columns):\\n@@@    tweet_id          2342 non-null int64\\n@@@    time_created      2342 non-null object\\n@@@    full_text         2342 non-null object\\n@@@    favorite_count    2342 non-null int64\\n@@@    retweet_count     2342 non-null int64\\n@@@    dtypes: int64(3), object(2)\\n@@@    memory usage: 91.6+ KB\\n@@@    \\n@@@\\n@@@## Observation\\n@@@\\n@@@df_json_tweets dataframe has 5 variables and 2343 observations. It has no missing values.\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@<a id=\\'B\\'></a>\\n@@@[Top](#Top)\\n@@@## B. Data Access Issues \\n@@@(The insights here are summarized from analysis in this subsection.)\\n@@@\\n@@@\\n@@@## Content Issues \\n@@@\\n@@@(Visual & Programmatically - completness, validity, accuracy, consistency)\\n@@@\\n@@@### twitter_archive dataframe\\n@@@    \\n@@@    - The expanded_url column, has some instances where the url is repeated multiple times in a cell separated by a comma\\n@@@    - The name column has non name strings such as None, a, an \\n@@@    - Rating_denominator as high as 80\\n@@@    - The following variables should be integers instead of floats: in_reply_to_status_id,in_reply_to_user_id,    \\n@@@      retweeted_status_id,retweeted_status_user_id \\n@@@    - Contains retweets\\n@@@\\n@@@\\n@@@### image_predictions dataframe\\n@@@\\n@@@    - p1, p2,p3: upper and lower case mixed together\\n@@@    - p1, p2,p3: dash and underscore mixed in string eg. black-and-tan_coonhound\\t\\n@@@    - Missing values when compared to twitter_archive dataframe\\n@@@\\n@@@###  tweet_json dataframe\\n@@@\\n@@@    - time_created should be a data/time object\\n@@@\\n@@@## Structural Issues\\n@@@\\n@@@(Visual & Programmatically -  variable(column), observation(row), unit(table))\\n@@@\\n@@@### twitter_archive dataframe\\n@@@\\n@@@    - The timestamp column contains two separate variables date and time. \\n@@@    - The anchor text in source column is repeated numerous times\\n@@@    - Variables called \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\' are different growth stages of a pet based on age.\\n@@@\\n@@@### image_predictions dataframe\\n@@@\\n@@@    - Merge the dataset with twitter_archive dataframe based on tweet_id\\n@@@\\n@@@###  tweet_json dataframe\\n@@@\\n@@@    - time_created could be further split into day, month and time \\n@@@    - Merge this dataframe with twitter_archive dataframe\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# function to find duplicates in a dataframe column\\n@@@# source:  https://stackoverflow.com/questions/15247628/how-to-find-duplicate-names-using-pandas\\n@@@def find_duplicates(df_column):\\n@@@    names=df_column.value_counts()\\n@@@    return(names[names>1])\\n@@@```\\n@@@\\n@@@# Analysing the twitter_archive dataframe\\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 16:23:56 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 00:17:27 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@There is presence of missing values in twitter archive table so this needs to be further investigated. The timestamp column contains two separate variables date and time. \\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.columns\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Index([\\'tweet_id\\', \\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'timestamp\\',\\n@@@           \\'source\\', \\'text\\', \\'retweeted_status_id\\', \\'retweeted_status_user_id\\',\\n@@@           \\'retweeted_status_timestamp\\', \\'expanded_urls\\', \\'rating_numerator\\',\\n@@@           \\'rating_denominator\\', \\'name\\', \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\'],\\n@@@          dtype=\\'object\\')\\n@@@\\n@@@\\n@@@\\n@@@Variables called \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\' are different growth stages of a pet and should be in one column.\\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.sample(5)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>815</th>\\n@@@      <td>771004394259247104</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2016-08-31 15:19:06 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>RT @katieornah: @dog_rates learning a lot at c...</td>\\n@@@      <td>7.710021e+17</td>\\n@@@      <td>1.732729e+09</td>\\n@@@      <td>2016-08-31 15:10:07 +0000</td>\\n@@@      <td>https://twitter.com/katieornah/status/77100213...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>pupper</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>682</th>\\n@@@      <td>788552643979468800</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2016-10-19 01:29:35 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>RT @dog_rates: Say hello to mad pupper. You kn...</td>\\n@@@      <td>7.363926e+17</td>\\n@@@      <td>4.196984e+09</td>\\n@@@      <td>2016-05-28 03:04:00 +0000</td>\\n@@@      <td>https://vine.co/v/iEggaEOiLO3,https://vine.co/...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>mad</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>pupper</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>254</th>\\n@@@      <td>844580511645339650</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-03-22 16:04:20 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Charlie. He wants to know if you have ...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/844580511...</td>\\n@@@      <td>11</td>\\n@@@      <td>10</td>\\n@@@      <td>Charlie</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>741</th>\\n@@@      <td>780496263422808064</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2016-09-26 19:56:24 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>RT @dog_rates: This is Bell. She likes holding...</td>\\n@@@      <td>7.424232e+17</td>\\n@@@      <td>4.196984e+09</td>\\n@@@      <td>2016-06-13 18:27:32 +0000</td>\\n@@@      <td>https://twitter.com/dog_rates/status/742423170...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>Bell</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>143</th>\\n@@@      <td>864197398364647424</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-05-15 19:14:50 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Paisley. She ate a flower just to prov...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/864197398...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Paisley</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.tweet_id)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: tweet_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@no duplicates in tweet id\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.source)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>     2221\\n@@@    <a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                          91\\n@@@    <a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                       33\\n@@@    <a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>      11\\n@@@    Name: source, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@the anchor text in source column is repeated numerous times - good candidate for categorical object\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.expanded_urls).head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    https://twitter.com/dog_rates/status/829501995190984704/photo/1,https://twitter.com/dog_rates/status/829501995190984704/photo/1    2\\n@@@    https://twitter.com/dog_rates/status/819227688460238848/photo/1                                                                    2\\n@@@    https://twitter.com/dog_rates/status/683391852557561860/photo/1                                                                    2\\n@@@    https://twitter.com/dog_rates/status/832369877331693569/photo/1                                                                    2\\n@@@    https://twitter.com/dog_rates/status/753375668877008896/photo/1                                                                    2\\n@@@    Name: expanded_urls, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@In the expanded_url column, there some instances where the url is repeated multiple times in a cell separated by a comma\\n@@@eg. https://twitter.com/dog_rates/status/791406955684368384/photo/1,https://twitter.com/dog_rates/status/791406955684368384/photo/1,https://twitter.com/dog_rates/status/791406955684368384/photo/1,https://twitter.com/dog_rates/status/791406955684368384/photo/1 -- may consider removing the repeated link after the comma \\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_numerator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    12     558\\n@@@    11     464\\n@@@    10     461\\n@@@    13     351\\n@@@    9      158\\n@@@    8      102\\n@@@    7       55\\n@@@    14      54\\n@@@    5       37\\n@@@    6       32\\n@@@    3       19\\n@@@    4       17\\n@@@    1        9\\n@@@    2        9\\n@@@    420      2\\n@@@    0        2\\n@@@    15       2\\n@@@    75       2\\n@@@    Name: rating_numerator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_denominator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    10    2333\\n@@@    11       3\\n@@@    50       3\\n@@@    80       2\\n@@@    20       2\\n@@@    Name: rating_denominator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.name).head(20)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    None       745\\n@@@    a           55\\n@@@    Charlie     12\\n@@@    Lucy        11\\n@@@    Oliver      11\\n@@@    Cooper      11\\n@@@    Penny       10\\n@@@    Tucker      10\\n@@@    Lola        10\\n@@@    Winston      9\\n@@@    Bo           9\\n@@@    Sadie        8\\n@@@    the          8\\n@@@    Toby         7\\n@@@    Bailey       7\\n@@@    Buddy        7\\n@@@    an           7\\n@@@    Daisy        7\\n@@@    Stanley      6\\n@@@    Koda         6\\n@@@    Name: name, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@The name column has non name strings such as None, a, an.  \\n@@@Could conside replacing non-name strings with nan.\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_numerator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    12     558\\n@@@    11     464\\n@@@    10     461\\n@@@    13     351\\n@@@    9      158\\n@@@    8      102\\n@@@    7       55\\n@@@    14      54\\n@@@    5       37\\n@@@    6       32\\n@@@    3       19\\n@@@    4       17\\n@@@    1        9\\n@@@    2        9\\n@@@    420      2\\n@@@    0        2\\n@@@    15       2\\n@@@    75       2\\n@@@    Name: rating_numerator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@Interesting to note that rating number of 420 occurs twice and it seems too \\'high - 420\\'. \\n@@@Instructions indicate that rating_numerator is almost more than 10. Also, interesting to note that there are 9 occurances of rating of 1 and 2.\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_denominator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    10    2333\\n@@@    11       3\\n@@@    50       3\\n@@@    80       2\\n@@@    20       2\\n@@@    Name: rating_denominator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@According to instructions, the denominator should be 10. But denominators as high as 80 can be observed.\\n@@@May consider changing them to 10.\\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2356 entries, 0 to 2355\\n@@@    Data columns (total 17 columns):\\n@@@    tweet_id                      2356 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2356 non-null object\\n@@@    source                        2356 non-null object\\n@@@    text                          2356 non-null object\\n@@@    retweeted_status_id           181 non-null float64\\n@@@    retweeted_status_user_id      181 non-null float64\\n@@@    retweeted_status_timestamp    181 non-null object\\n@@@    expanded_urls                 2297 non-null object\\n@@@    rating_numerator              2356 non-null int64\\n@@@    rating_denominator            2356 non-null int64\\n@@@    name                          2356 non-null object\\n@@@    doggo                         2356 non-null object\\n@@@    floofer                       2356 non-null object\\n@@@    pupper                        2356 non-null object\\n@@@    puppo                         2356 non-null object\\n@@@    dtypes: float64(4), int64(3), object(10)\\n@@@    memory usage: 313.0+ KB\\n@@@    \\n@@@\\n@@@The table has 17 variables and 2356 observations. The table is organized by 2356 unique tweet_ids.\\n@@@\\n@@@There is presence of missing values in in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, \\n@@@retweeted_status_user_id,retweeted_status_timestamp, expanded_urls.\\n@@@\\n@@@The following variables should be integers instead of floats: in_reply_to_status_id,in_reply_to_user_id, retweeted_status_id,retweeted_status_user_id.  \\n@@@\\n@@@Timestamp is a string object instead of a date time object.\\n@@@\\n@@@retweeted_status_id count of 181 indicates that there are 181 tweets that are actually retweets and will need to be removed from the dataframe as we will be only working with original tweets and not retweets.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@# Analysing the image_predictions dataframe\\n@@@\\n@@@\\n@@@```python\\n@@@df_image_predictions.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>img_num</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>666020888022790149</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Welsh_springer_spaniel</td>\\n@@@      <td>0.465074</td>\\n@@@      <td>True</td>\\n@@@      <td>collie</td>\\n@@@      <td>0.156665</td>\\n@@@      <td>True</td>\\n@@@      <td>Shetland_sheepdog</td>\\n@@@      <td>0.061428</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>666029285002620928</td>\\n@@@      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.506826</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.074192</td>\\n@@@      <td>True</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.072010</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>666033412701032449</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>German_shepherd</td>\\n@@@      <td>0.596461</td>\\n@@@      <td>True</td>\\n@@@      <td>malinois</td>\\n@@@      <td>0.138584</td>\\n@@@      <td>True</td>\\n@@@      <td>bloodhound</td>\\n@@@      <td>0.116197</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>666044226329800704</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.408143</td>\\n@@@      <td>True</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.360687</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.222752</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>666049248165822465</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.560311</td>\\n@@@      <td>True</td>\\n@@@      <td>Rottweiler</td>\\n@@@      <td>0.243682</td>\\n@@@      <td>True</td>\\n@@@      <td>Doberman</td>\\n@@@      <td>0.154629</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@p1, p2,p3: upper and lower case mixed together\\n@@@\\n@@@\\n@@@```python\\n@@@df_image_predictions.sample(5)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>img_num</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>892</th>\\n@@@      <td>699413908797464576</td>\\n@@@      <td>https://pbs.twimg.com/media/CbTRPXdW8AQMZf7.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Samoyed</td>\\n@@@      <td>0.517479</td>\\n@@@      <td>True</td>\\n@@@      <td>malamute</td>\\n@@@      <td>0.155935</td>\\n@@@      <td>True</td>\\n@@@      <td>Eskimo_dog</td>\\n@@@      <td>0.095001</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1967</th>\\n@@@      <td>867900495410671616</td>\\n@@@      <td>https://pbs.twimg.com/media/DAtm5MkXoAA4R6P.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Labrador_retriever</td>\\n@@@      <td>0.522644</td>\\n@@@      <td>True</td>\\n@@@      <td>kuvasz</td>\\n@@@      <td>0.332461</td>\\n@@@      <td>True</td>\\n@@@      <td>dalmatian</td>\\n@@@      <td>0.032008</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1397</th>\\n@@@      <td>768193404517830656</td>\\n@@@      <td>https://pbs.twimg.com/media/Cqkr0wiW8AAn2Oi.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>lion</td>\\n@@@      <td>0.396984</td>\\n@@@      <td>False</td>\\n@@@      <td>ram</td>\\n@@@      <td>0.300851</td>\\n@@@      <td>False</td>\\n@@@      <td>cheetah</td>\\n@@@      <td>0.094474</td>\\n@@@      <td>False</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>771</th>\\n@@@      <td>689517482558820352</td>\\n@@@      <td>https://pbs.twimg.com/media/CZGofjJW0AINjN9.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Pembroke</td>\\n@@@      <td>0.799319</td>\\n@@@      <td>True</td>\\n@@@      <td>Cardigan</td>\\n@@@      <td>0.189537</td>\\n@@@      <td>True</td>\\n@@@      <td>papillon</td>\\n@@@      <td>0.003386</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>919</th>\\n@@@      <td>701889187134500865</td>\\n@@@      <td>https://pbs.twimg.com/media/Cb2cfd9WAAEL-zk.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>French_bulldog</td>\\n@@@      <td>0.902856</td>\\n@@@      <td>True</td>\\n@@@      <td>Staffordshire_bullterrier</td>\\n@@@      <td>0.022634</td>\\n@@@      <td>True</td>\\n@@@      <td>soap_dispenser</td>\\n@@@      <td>0.011973</td>\\n@@@      <td>False</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@p1, p2,p3: dash and underscore mixed in string eg. black-and-tan_coonhound\\t\\n@@@\\n@@@\\n@@@```python\\n@@@df_image_predictions.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2075 entries, 0 to 2074\\n@@@    Data columns (total 12 columns):\\n@@@    tweet_id    2075 non-null int64\\n@@@    jpg_url     2075 non-null object\\n@@@    img_num     2075 non-null int64\\n@@@    p1          2075 non-null object\\n@@@    p1_conf     2075 non-null float64\\n@@@    p1_dog      2075 non-null bool\\n@@@    p2          2075 non-null object\\n@@@    p2_conf     2075 non-null float64\\n@@@    p2_dog      2075 non-null bool\\n@@@    p3          2075 non-null object\\n@@@    p3_conf     2075 non-null float64\\n@@@    p3_dog      2075 non-null bool\\n@@@    dtypes: bool(3), float64(3), int64(2), object(4)\\n@@@    memory usage: 152.1+ KB\\n@@@    \\n@@@\\n@@@No missing values in this dataset.\\n@@@\\n@@@This dataset should be merged with the archived dataset based on the tweet ids becuase this dataset is predicting the images of the tweet ids. In that case, this dataset will have missing values as the archive dataset has 2355 observations and this dataset\\n@@@has 2075 instances.\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_image_predictions.tweet_id)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: tweet_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@no duplicates in tweet id\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_image_predictions.jpg_url).head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    https://pbs.twimg.com/ext_tw_video_thumb/675354114423808004/pu/img/qL1R_nGLqa6lmkOx.jpg    2\\n@@@    https://pbs.twimg.com/media/DA7iHL5U0AA1OQo.jpg                                            2\\n@@@    https://pbs.twimg.com/media/CYLDikFWEAAIy1y.jpg                                            2\\n@@@    https://pbs.twimg.com/media/CzG425nWgAAnP7P.jpg                                            2\\n@@@    https://pbs.twimg.com/media/CkjMx99UoAM2B1a.jpg                                            2\\n@@@    Name: jpg_url, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@numerous urls are repeated in the jpg_url column - this could or could not be an issue in future\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@# Analysing the tweet_json dataframe\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>time_created</th>\\n@@@      <th>full_text</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>Tue Aug 01 16:23:56 +0000 2017</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>38492</td>\\n@@@      <td>8480</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>Tue Aug 01 00:17:27 +0000 2017</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>32986</td>\\n@@@      <td>6241</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>Mon Jul 31 00:18:03 +0000 2017</td>\\n@@@      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\\n@@@      <td>24840</td>\\n@@@      <td>4137</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>Sun Jul 30 15:58:51 +0000 2017</td>\\n@@@      <td>This is Darla. She commenced a snooze mid meal...</td>\\n@@@      <td>41865</td>\\n@@@      <td>8598</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>Sat Jul 29 16:00:24 +0000 2017</td>\\n@@@      <td>This is Franklin. He would like you to stop ca...</td>\\n@@@      <td>40029</td>\\n@@@      <td>9336</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@time_created could be further split into day, month and time.\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.sample(5)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>time_created</th>\\n@@@      <th>full_text</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>2069</th>\\n@@@      <td>670811965569282048</td>\\n@@@      <td>Sun Nov 29 03:50:10 +0000 2015</td>\\n@@@      <td>Meet Maggie. She enjoys her stick in the yard....</td>\\n@@@      <td>1162</td>\\n@@@      <td>281</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2227</th>\\n@@@      <td>667915453470232577</td>\\n@@@      <td>Sat Nov 21 04:00:28 +0000 2015</td>\\n@@@      <td>Meet Otis. He is a Peruvian Quartzite. Pic spo...</td>\\n@@@      <td>216</td>\\n@@@      <td>58</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1886</th>\\n@@@      <td>674664755118911488</td>\\n@@@      <td>Wed Dec 09 18:59:46 +0000 2015</td>\\n@@@      <td>This is Rodman. He\\'s getting destroyed by the ...</td>\\n@@@      <td>957</td>\\n@@@      <td>270</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1339</th>\\n@@@      <td>703769065844768768</td>\\n@@@      <td>Sun Feb 28 02:29:55 +0000 2016</td>\\n@@@      <td>When you\\'re trying to watch your favorite tv s...</td>\\n@@@      <td>3494</td>\\n@@@      <td>1231</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1974</th>\\n@@@      <td>672834301050937345</td>\\n@@@      <td>Fri Dec 04 17:46:12 +0000 2015</td>\\n@@@      <td>This is Ed. He\\'s not mad, just disappointed. 1...</td>\\n@@@      <td>1352</td>\\n@@@      <td>595</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.describe()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>count</th>\\n@@@      <td>2.342000e+03</td>\\n@@@      <td>2342.000000</td>\\n@@@      <td>2342.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>mean</th>\\n@@@      <td>7.422646e+17</td>\\n@@@      <td>8042.367635</td>\\n@@@      <td>2980.833049</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>std</th>\\n@@@      <td>6.837466e+16</td>\\n@@@      <td>12364.650672</td>\\n@@@      <td>4990.628083</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>min</th>\\n@@@      <td>6.660209e+17</td>\\n@@@      <td>0.000000</td>\\n@@@      <td>0.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>25%</th>\\n@@@      <td>6.783509e+17</td>\\n@@@      <td>1394.250000</td>\\n@@@      <td>599.250000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>50%</th>\\n@@@      <td>7.186224e+17</td>\\n@@@      <td>3509.000000</td>\\n@@@      <td>1395.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>75%</th>\\n@@@      <td>7.987010e+17</td>\\n@@@      <td>9881.750000</td>\\n@@@      <td>3478.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>max</th>\\n@@@      <td>8.924206e+17</td>\\n@@@      <td>162143.000000</td>\\n@@@      <td>84152.000000</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@There is a tweet that got 142,306 favorite counts and 76,667 retweet counts. It would be nice to investigate this further in visuals to see if it is the same tweet. Also what days do most tweets occur?\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_json_tweets.tweet_id)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: tweet_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@tweet_id is not duplicated.\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2342 entries, 0 to 2341\\n@@@    Data columns (total 5 columns):\\n@@@    tweet_id          2342 non-null int64\\n@@@    time_created      2342 non-null object\\n@@@    full_text         2342 non-null object\\n@@@    favorite_count    2342 non-null int64\\n@@@    retweet_count     2342 non-null int64\\n@@@    dtypes: int64(3), object(2)\\n@@@    memory usage: 91.6+ KB\\n@@@    \\n@@@\\n@@@Since this dataframe\\'s tweet id is based on the tweet id of the twitter_archive dataframe\\'s tweet id, we can merge both these\\n@@@tables into one table and add the favorite_count annd retweet_count from json_tweets dataframe to twitter_archive dataframe.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@<a id=\\'C\\'></a>\\n@@@[Top](#Top)\\n@@@# C. Data Cleaning \\n@@@(Define, code, test )\\n@@@- code and test are addressed separately for each issue.\\n@@@\\n@@@### Define - Content Issues\\n@@@#### Cleaning the twitter_archive dataframe \\n@@@\\n@@@1. Format the timestamp to datetime format\\n@@@2. Add columns for the month, weekday and hour the tweet was created\\n@@@3. Remove all retweets\\n@@@4. Convert source to categorical value\\n@@@5. Remove same multiple urls in expanded_urls variable \\n@@@6. Change the rating denominator to 10\\n@@@7. Remove non name characters from the name variable\\n@@@8. Only keep necessary columns\\n@@@\\n@@@#### Cleaning image_predictions table\\n@@@1. Drop img_num variable\\n@@@\\n@@@#### Cleaning json tweets table\\n@@@1. Drop full_text and time_created variables\\n@@@\\n@@@### Define - Structural Issues\\n@@@1. Merge cleaned twitter archive table with cleaned image predictions table to create a df_main table\\n@@@2. Merge the df_main table with cleaned json tweets table\\n@@@3. For df_main dataframe, merge  \\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\' variables into one column \\n@@@\\n@@@## Cleaning the twitter_archive dataframe \\n@@@\\n@@@\\n@@@```python\\n@@@# make a copy of the twitter_archive dataframe\\n@@@df_twitter_archive_clean=df_twitter_archive.copy()\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# 1. Format the timestamp to datetime format\\n@@@\\n@@@#### code\\n@@@# remove the +0000 from timestamp\\n@@@df_twitter_archive_clean.timestamp=df_twitter_archive_clean.timestamp.str[:-6]\\n@@@\\n@@@# convert the whole column proper date format using the datetime function\\n@@@df_twitter_archive_clean[\\'timestamp\\'] =  pd.to_datetime(df_twitter_archive_clean[\\'timestamp\\'], format=\\'%Y-%m-%d %X\\')\\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2356 entries, 0 to 2355\\n@@@    Data columns (total 17 columns):\\n@@@    tweet_id                      2356 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2356 non-null datetime64[ns]\\n@@@    source                        2356 non-null object\\n@@@    text                          2356 non-null object\\n@@@    retweeted_status_id           181 non-null float64\\n@@@    retweeted_status_user_id      181 non-null float64\\n@@@    retweeted_status_timestamp    181 non-null object\\n@@@    expanded_urls                 2297 non-null object\\n@@@    rating_numerator              2356 non-null int64\\n@@@    rating_denominator            2356 non-null int64\\n@@@    name                          2356 non-null object\\n@@@    doggo                         2356 non-null object\\n@@@    floofer                       2356 non-null object\\n@@@    pupper                        2356 non-null object\\n@@@    puppo                         2356 non-null object\\n@@@    dtypes: datetime64[ns](1), float64(4), int64(3), object(9)\\n@@@    memory usage: 313.0+ KB\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 2. Add columns for the month, weekday and hour the tweet was created\\n@@@\\n@@@#### code\\n@@@#df_twitter_clean.timestamp[0].hour\\n@@@df_twitter_archive_clean[\\'timestamp_month\\']=df_twitter_archive_clean.timestamp.map(lambda a: a.month)\\n@@@df_twitter_archive_clean[\\'timestamp_weekday\\']=df_twitter_archive_clean.timestamp.map(lambda a: a.weekday())\\n@@@df_twitter_archive_clean[\\'timestamp_hour\\']=df_twitter_archive_clean.timestamp.map(lambda a: a.hour)\\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@      <th>timestamp_month</th>\\n@@@      <th>timestamp_weekday</th>\\n@@@      <th>timestamp_hour</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>16</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>0</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# 3. Remove all retweets\\n@@@# retweeted_status_id contains id of retweets so remove all retweets and only keep NaN\\n@@@\\n@@@#### code\\n@@@# df_twitter_clean.retweeted_status_id\\n@@@index_original_tweet=pd.isnull(df_twitter_archive_clean[\\'retweeted_status_id\\'])\\n@@@df_twitter_archive_clean=df_twitter_archive_clean[index_original_tweet]\\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.retweeted_status_id.value_counts() # shows no values\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: retweeted_status_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# 4. Convert source to categorical value\\n@@@\\n@@@#### code\\n@@@#view the value counts\\n@@@print(df_twitter_archive_clean.source.value_counts())\\n@@@\\n@@@\\n@@@# create a dictionary for mapping\\n@@@di_source = {\\'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\\':\\'Twitter for iPhone\\',\\n@@@            \\'<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>\\':\\'Vine - Make a Scene\\',\\n@@@            \\'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>\\':\\'Twitter Web Client\\',\\n@@@            \\'<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>\\':\\'TweetDeck\\'}\\n@@@\\n@@@# map the dictionary \\n@@@df_twitter_archive_clean[\\'source\\']=df_twitter_archive_clean[\\'source\\'].replace(di_source)\\n@@@\\n@@@print(\\'\\\\n\\\\n\\')\\n@@@print(df_twitter_archive_clean[\\'source\\'].value_counts())\\n@@@print(\\'\\\\n\\\\n\\')\\n@@@\\n@@@# convert the source variable to a categorical object\\n@@@df_twitter_archive_clean[\\'source\\']=df_twitter_archive_clean[\\'source\\'].astype(\\'category\\')\\n@@@\\n@@@#### test \\n@@@# .info() hows that source variable is now sa category \\n@@@print(df_twitter_archive_clean.info())\\n@@@```\\n@@@\\n@@@    <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>     2042\\n@@@    <a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                          91\\n@@@    <a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                       31\\n@@@    <a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>      11\\n@@@    Name: source, dtype: int64\\n@@@    \\n@@@    \\n@@@    \\n@@@    Twitter for iPhone     2042\\n@@@    Vine - Make a Scene      91\\n@@@    Twitter Web Client       31\\n@@@    TweetDeck                11\\n@@@    Name: source, dtype: int64\\n@@@    \\n@@@    \\n@@@    \\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    Int64Index: 2175 entries, 0 to 2355\\n@@@    Data columns (total 20 columns):\\n@@@    tweet_id                      2175 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2175 non-null datetime64[ns]\\n@@@    source                        2175 non-null category\\n@@@    text                          2175 non-null object\\n@@@    retweeted_status_id           0 non-null float64\\n@@@    retweeted_status_user_id      0 non-null float64\\n@@@    retweeted_status_timestamp    0 non-null object\\n@@@    expanded_urls                 2117 non-null object\\n@@@    rating_numerator              2175 non-null int64\\n@@@    rating_denominator            2175 non-null int64\\n@@@    name                          2175 non-null object\\n@@@    doggo                         2175 non-null object\\n@@@    floofer                       2175 non-null object\\n@@@    pupper                        2175 non-null object\\n@@@    puppo                         2175 non-null object\\n@@@    timestamp_month               2175 non-null int64\\n@@@    timestamp_weekday             2175 non-null int64\\n@@@    timestamp_hour                2175 non-null int64\\n@@@    dtypes: category(1), datetime64[ns](1), float64(4), int64(6), object(8)\\n@@@    memory usage: 342.2+ KB\\n@@@    None\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 5. Remove same multiple urls in expanded_urls variable \\n@@@\\n@@@#### code\\n@@@# first print the urls to screen\\n@@@df_twitter_archive_clean.expanded_urls.head(10).map(lambda a : print(a))\\n@@@```\\n@@@\\n@@@    https://twitter.com/dog_rates/status/892420643555336193/photo/1\\n@@@    https://twitter.com/dog_rates/status/892177421306343426/photo/1\\n@@@    https://twitter.com/dog_rates/status/891815181378084864/photo/1\\n@@@    https://twitter.com/dog_rates/status/891689557279858688/photo/1\\n@@@    https://twitter.com/dog_rates/status/891327558926688256/photo/1,https://twitter.com/dog_rates/status/891327558926688256/photo/1\\n@@@    https://twitter.com/dog_rates/status/891087950875897856/photo/1\\n@@@    https://gofundme.com/ydvmve-surgery-for-jax,https://twitter.com/dog_rates/status/890971913173991426/photo/1\\n@@@    https://twitter.com/dog_rates/status/890729181411237888/photo/1,https://twitter.com/dog_rates/status/890729181411237888/photo/1\\n@@@    https://twitter.com/dog_rates/status/890609185150312448/photo/1\\n@@@    https://twitter.com/dog_rates/status/890240255349198849/photo/1\\n@@@    \\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    0    None\\n@@@    1    None\\n@@@    2    None\\n@@@    3    None\\n@@@    4    None\\n@@@    5    None\\n@@@    6    None\\n@@@    7    None\\n@@@    8    None\\n@@@    9    None\\n@@@    Name: expanded_urls, dtype: object\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@#### code continued..\\n@@@# use the str.split function to split on comma and save the first column\\n@@@tmp=df_twitter_archive_clean.expanded_urls.str.split(\\',\\', expand=True)[0]\\n@@@#tmp.map(lambda a : print(a))\\n@@@\\n@@@\\n@@@#### test \\n@@@# print the formatted urp to screen for a visual confirmation\\n@@@df_twitter_archive_clean.expanded_urls=tmp.copy()\\n@@@df_twitter_archive_clean.expanded_urls.head(10).map(lambda a : print(a))\\n@@@```\\n@@@\\n@@@    https://twitter.com/dog_rates/status/892420643555336193/photo/1\\n@@@    https://twitter.com/dog_rates/status/892177421306343426/photo/1\\n@@@    https://twitter.com/dog_rates/status/891815181378084864/photo/1\\n@@@    https://twitter.com/dog_rates/status/891689557279858688/photo/1\\n@@@    https://twitter.com/dog_rates/status/891327558926688256/photo/1\\n@@@    https://twitter.com/dog_rates/status/891087950875897856/photo/1\\n@@@    https://gofundme.com/ydvmve-surgery-for-jax\\n@@@    https://twitter.com/dog_rates/status/890729181411237888/photo/1\\n@@@    https://twitter.com/dog_rates/status/890609185150312448/photo/1\\n@@@    https://twitter.com/dog_rates/status/890240255349198849/photo/1\\n@@@    \\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    0    None\\n@@@    1    None\\n@@@    2    None\\n@@@    3    None\\n@@@    4    None\\n@@@    5    None\\n@@@    6    None\\n@@@    7    None\\n@@@    8    None\\n@@@    9    None\\n@@@    Name: expanded_urls, dtype: object\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# 6. Change the rating denominator to 10\\n@@@\\n@@@#### code\\n@@@print(df_twitter_archive_clean.rating_denominator.value_counts())\\n@@@df_twitter_archive_clean.rating_denominator=10\\n@@@\\n@@@#### test\\n@@@print(\\'\\\\n\\\\n\\')\\n@@@print(df_twitter_archive_clean.rating_denominator.value_counts())\\n@@@\\n@@@```\\n@@@\\n@@@    10     2153\\n@@@    50        3\\n@@@    80        2\\n@@@    11        2\\n@@@    20        2\\n@@@    2         1\\n@@@    16        1\\n@@@    40        1\\n@@@    70        1\\n@@@    15        1\\n@@@    90        1\\n@@@    110       1\\n@@@    120       1\\n@@@    130       1\\n@@@    150       1\\n@@@    170       1\\n@@@    7         1\\n@@@    0         1\\n@@@    Name: rating_denominator, dtype: int64\\n@@@    \\n@@@    \\n@@@    \\n@@@    10    2175\\n@@@    Name: rating_denominator, dtype: int64\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 7. Remove non name characters from the name variable\\n@@@# Replace the non name strings \\'None\\',\\'a\\', \\'an\\' with Nan\\n@@@\\n@@@#### code\\n@@@print(df_twitter_archive_clean.name.value_counts()) # shows there is None,a,an in name value \\n@@@```\\n@@@\\n@@@    None         680\\n@@@    a             55\\n@@@    Charlie       11\\n@@@    Lucy          11\\n@@@    Cooper        10\\n@@@    Oliver        10\\n@@@    Penny          9\\n@@@    Tucker         9\\n@@@    Sadie          8\\n@@@    the            8\\n@@@    Winston        8\\n@@@    Lola           8\\n@@@    Daisy          7\\n@@@    Toby           7\\n@@@    Bailey         6\\n@@@    Jax            6\\n@@@    Bo             6\\n@@@    Koda           6\\n@@@    Stanley        6\\n@@@    Bella          6\\n@@@    Oscar          6\\n@@@    an             6\\n@@@    Dave           5\\n@@@    Milo           5\\n@@@    Bentley        5\\n@@@    Rusty          5\\n@@@    Buddy          5\\n@@@    Louis          5\\n@@@    Chester        5\\n@@@    Leo            5\\n@@@                ... \\n@@@    Levi           1\\n@@@    Aubie          1\\n@@@    Asher          1\\n@@@    Shnuggles      1\\n@@@    Amber          1\\n@@@    Astrid         1\\n@@@    Beemo          1\\n@@@    Aldrick        1\\n@@@    Julio          1\\n@@@    Laika          1\\n@@@    Chef           1\\n@@@    Sandra         1\\n@@@    Eve            1\\n@@@    Newt           1\\n@@@    Zeek           1\\n@@@    Filup          1\\n@@@    Hubertson      1\\n@@@    Sierra         1\\n@@@    Alf            1\\n@@@    Skittle        1\\n@@@    Charleson      1\\n@@@    Tedrick        1\\n@@@    Steve          1\\n@@@    Hanz           1\\n@@@    Akumi          1\\n@@@    Wafer          1\\n@@@    Happy          1\\n@@@    Angel          1\\n@@@    Benny          1\\n@@@    such           1\\n@@@    Name: name, Length: 956, dtype: int64\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@#### code continued ...\\n@@@# Try using Regex for a one liner\\n@@@#Replace \\'None\\' with Nan\\n@@@df_twitter_archive_clean[\\'name\\']=df_twitter_archive_clean[\\'name\\'].replace(\\'None\\', np.NaN, )\\n@@@# Replace \\'a\\' with Nan\\n@@@df_twitter_archive_clean[\\'name\\']=df_twitter_archive_clean[\\'name\\'].replace(\\'a\\', np.NaN, )\\n@@@# Replace \\'an\\' with Nan\\n@@@df_twitter_archive_clean[\\'name\\']=df_twitter_archive_clean[\\'name\\'].replace(\\'an\\', np.NaN, )\\n@@@\\n@@@#### test\\n@@@print(df_twitter_archive_clean[\\'name\\'].value_counts())\\n@@@# output shows no occurance of None, a, an\\n@@@```\\n@@@\\n@@@    Lucy         11\\n@@@    Charlie      11\\n@@@    Cooper       10\\n@@@    Oliver       10\\n@@@    Tucker        9\\n@@@    Penny         9\\n@@@    Winston       8\\n@@@    Lola          8\\n@@@    Sadie         8\\n@@@    the           8\\n@@@    Daisy         7\\n@@@    Toby          7\\n@@@    Jax           6\\n@@@    Koda          6\\n@@@    Bella         6\\n@@@    Oscar         6\\n@@@    Bailey        6\\n@@@    Bo            6\\n@@@    Stanley       6\\n@@@    Rusty         5\\n@@@    Chester       5\\n@@@    Buddy         5\\n@@@    Scout         5\\n@@@    Leo           5\\n@@@    Louis         5\\n@@@    Milo          5\\n@@@    Bentley       5\\n@@@    Dave          5\\n@@@    Jack          4\\n@@@    Archie        4\\n@@@                 ..\\n@@@    Mimosa        1\\n@@@    Levi          1\\n@@@    Aubie         1\\n@@@    Asher         1\\n@@@    Aldrick       1\\n@@@    Benny         1\\n@@@    Angel         1\\n@@@    Happy         1\\n@@@    Diogi         1\\n@@@    Trigger       1\\n@@@    Antony        1\\n@@@    Julio         1\\n@@@    Laika         1\\n@@@    Chef          1\\n@@@    Sandra        1\\n@@@    Eve           1\\n@@@    Newt          1\\n@@@    Zeek          1\\n@@@    Filup         1\\n@@@    Hubertson     1\\n@@@    Sierra        1\\n@@@    Alf           1\\n@@@    Skittle       1\\n@@@    Charleson     1\\n@@@    Tedrick       1\\n@@@    Steve         1\\n@@@    Hanz          1\\n@@@    Akumi         1\\n@@@    Wafer         1\\n@@@    such          1\\n@@@    Name: name, Length: 953, dtype: int64\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 8. Only keep necessary columns\\n@@@# Drop the following columns : \\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'retweeted_status_id\\', \\n@@@#                              \\'retweeted_status_user_id\\',\\'retweeted_status_timestamp\\'\\n@@@\\n@@@#### code\\n@@@print(df_twitter_archive_clean.columns)\\n@@@\\n@@@drop_columns = [\\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'retweeted_status_id\\', \\n@@@                \\'retweeted_status_user_id\\',\\'retweeted_status_timestamp\\']\\n@@@\\n@@@df_twitter_archive_clean=df_twitter_archive_clean.drop(drop_columns, axis=1)  # df.columns is zero-based pd.Index \\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.head()\\n@@@```\\n@@@\\n@@@    Index([\\'tweet_id\\', \\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'timestamp\\',\\n@@@           \\'source\\', \\'text\\', \\'retweeted_status_id\\', \\'retweeted_status_user_id\\',\\n@@@           \\'retweeted_status_timestamp\\', \\'expanded_urls\\', \\'rating_numerator\\',\\n@@@           \\'rating_denominator\\', \\'name\\', \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\',\\n@@@           \\'timestamp_month\\', \\'timestamp_weekday\\', \\'timestamp_hour\\'],\\n@@@          dtype=\\'object\\')\\n@@@    \\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@      <th>timestamp_month</th>\\n@@@      <th>timestamp_weekday</th>\\n@@@      <th>timestamp_hour</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>16</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>0</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>2017-07-31 00:18:03</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/891815181...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>Archie</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>7</td>\\n@@@      <td>0</td>\\n@@@      <td>0</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>2017-07-30 15:58:51</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Darla. She commenced a snooze mid meal...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/891689557...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Darla</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>7</td>\\n@@@      <td>6</td>\\n@@@      <td>15</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>2017-07-29 16:00:24</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Franklin. He would like you to stop ca...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/891327558...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>Franklin</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>7</td>\\n@@@      <td>5</td>\\n@@@      <td>16</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Clean image_predictions table\\n@@@\\n@@@\\n@@@```python\\n@@@# 1. Drop img_num variable\\n@@@\\n@@@#### code\\n@@@df_image_predictions_clean=df_image_predictions.copy()\\n@@@#df_image_predictions_clean.head()\\n@@@df_image_predictions_clean=df_image_predictions_clean.drop(\\'img_num\\',axis=1)\\n@@@\\n@@@#### test\\n@@@df_image_predictions_clean.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>666020888022790149</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\\n@@@      <td>Welsh_springer_spaniel</td>\\n@@@      <td>0.465074</td>\\n@@@      <td>True</td>\\n@@@      <td>collie</td>\\n@@@      <td>0.156665</td>\\n@@@      <td>True</td>\\n@@@      <td>Shetland_sheepdog</td>\\n@@@      <td>0.061428</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>666029285002620928</td>\\n@@@      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.506826</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.074192</td>\\n@@@      <td>True</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.072010</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>666033412701032449</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\\n@@@      <td>German_shepherd</td>\\n@@@      <td>0.596461</td>\\n@@@      <td>True</td>\\n@@@      <td>malinois</td>\\n@@@      <td>0.138584</td>\\n@@@      <td>True</td>\\n@@@      <td>bloodhound</td>\\n@@@      <td>0.116197</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>666044226329800704</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.408143</td>\\n@@@      <td>True</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.360687</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.222752</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>666049248165822465</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.560311</td>\\n@@@      <td>True</td>\\n@@@      <td>Rottweiler</td>\\n@@@      <td>0.243682</td>\\n@@@      <td>True</td>\\n@@@      <td>Doberman</td>\\n@@@      <td>0.154629</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Clean json tweets table\\n@@@\\n@@@\\n@@@```python\\n@@@# 1. Drop full_text and time_created variables\\n@@@\\n@@@#### code\\n@@@df_json_tweets_cleaned=df_json_tweets.copy()\\n@@@drop_columns=[\\'full_text\\',\\'time_created\\']\\n@@@df_json_tweets_cleaned=df_json_tweets_cleaned.drop(drop_columns,axis=1)\\n@@@\\n@@@#### test\\n@@@df_json_tweets_cleaned.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>38492</td>\\n@@@      <td>8480</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>32986</td>\\n@@@      <td>6241</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>24840</td>\\n@@@      <td>4137</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>41865</td>\\n@@@      <td>8598</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>40029</td>\\n@@@      <td>9336</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Structural Issue 1: Merge cleaned twitter archive table with cleaned image predictions table to create a df_main table\\n@@@\\n@@@\\n@@@```python\\n@@@# Structural Issue 1: Merge cleaned twitter archive table with cleaned image predictions table to create a df_main table\\n@@@\\n@@@#### code\\n@@@df_main=pd.merge(df_twitter_archive_clean,df_image_predictions_clean, on=\\'tweet_id\\', how=\\'left\\')\\n@@@\\n@@@#### test\\n@@@df_main.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>...</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>...</td>\\n@@@      <td>https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg</td>\\n@@@      <td>orange</td>\\n@@@      <td>0.097049</td>\\n@@@      <td>False</td>\\n@@@      <td>bagel</td>\\n@@@      <td>0.085851</td>\\n@@@      <td>False</td>\\n@@@      <td>banana</td>\\n@@@      <td>0.076110</td>\\n@@@      <td>False</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>...</td>\\n@@@      <td>https://pbs.twimg.com/media/DGGmoV4XsAAUL6n.jpg</td>\\n@@@      <td>Chihuahua</td>\\n@@@      <td>0.323581</td>\\n@@@      <td>True</td>\\n@@@      <td>Pekinese</td>\\n@@@      <td>0.090647</td>\\n@@@      <td>True</td>\\n@@@      <td>papillon</td>\\n@@@      <td>0.068957</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@<p>2 rows Ã— 25 columns</p>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Structural Issue 2: Merge the df_main table with cleaned json tweets table\\n@@@\\n@@@\\n@@@```python\\n@@@# Structural Issue 2: Merge the df_main table with cleaned json tweets table\\n@@@\\n@@@#### code\\n@@@df_main=pd.merge(df_main,df_json_tweets_cleaned,on=\\'tweet_id\\', how=\\'left\\')\\n@@@\\n@@@#### test\\n@@@df_main.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    Int64Index: 2175 entries, 0 to 2174\\n@@@    Data columns (total 27 columns):\\n@@@    tweet_id              2175 non-null int64\\n@@@    timestamp             2175 non-null datetime64[ns]\\n@@@    source                2175 non-null category\\n@@@    text                  2175 non-null object\\n@@@    expanded_urls         2117 non-null object\\n@@@    rating_numerator      2175 non-null int64\\n@@@    rating_denominator    2175 non-null int64\\n@@@    name                  1434 non-null object\\n@@@    doggo                 2175 non-null object\\n@@@    floofer               2175 non-null object\\n@@@    pupper                2175 non-null object\\n@@@    puppo                 2175 non-null object\\n@@@    timestamp_month       2175 non-null int64\\n@@@    timestamp_weekday     2175 non-null int64\\n@@@    timestamp_hour        2175 non-null int64\\n@@@    jpg_url               1994 non-null object\\n@@@    p1                    1994 non-null object\\n@@@    p1_conf               1994 non-null float64\\n@@@    p1_dog                1994 non-null object\\n@@@    p2                    1994 non-null object\\n@@@    p2_conf               1994 non-null float64\\n@@@    p2_dog                1994 non-null object\\n@@@    p3                    1994 non-null object\\n@@@    p3_conf               1994 non-null float64\\n@@@    p3_dog                1994 non-null object\\n@@@    favorite_count        2174 non-null float64\\n@@@    retweet_count         2174 non-null float64\\n@@@    dtypes: category(1), datetime64[ns](1), float64(5), int64(6), object(14)\\n@@@    memory usage: 461.1+ KB\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@# Structural Issue 3: For df_main dataframe, merge  \\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\' variables into one column \\n@@@\\n@@@\\n@@@```python\\n@@@# Structural Issue 3: melt variables \\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\' into one column\\n@@@\\n@@@#### code\\n@@@# copy the variables to a tmp dataframe\\n@@@tmp=df_main[[\\'tweet_id\\',\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\']].copy()\\n@@@\\n@@@# melt the variables\\n@@@tmp=pd.melt(tmp,id_vars=[\\'tweet_id\\'], value_vars=[\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\'],value_name=\\'growth_stage\\')\\n@@@\\n@@@# drop the column called variable\\n@@@tmp=tmp.drop(\\'variable\\', axis=1)\\n@@@\\n@@@# replace the None with NaN in growth_stage column\\n@@@tmp[\\'growth_stage\\']=tmp[\\'growth_stage\\'].replace(\\'None\\', np.NaN, )\\n@@@\\n@@@#drop rows containing na\\'s because there are too many rows with na\\'s\\n@@@tmp=tmp.dropna()\\n@@@\\n@@@tmp.growth_stage.value_counts()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    pupper     234\\n@@@    doggo       87\\n@@@    puppo       25\\n@@@    floofer     10\\n@@@    Name: growth_stage, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@#### code continued ...\\n@@@# remove the following variables (\\'tweet_id\\',\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\') from the df_main table\\n@@@drop_columns = [\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\']\\n@@@df_main = df_main.drop(drop_columns,axis=1)\\n@@@\\n@@@# merge df_main with the tmp dataframe containing the growth_stage column\\n@@@df_main=pd.merge(df_main,tmp,on=\\'tweet_id\\', how=\\'left\\')\\n@@@\\n@@@df_main.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>timestamp_month</th>\\n@@@      <th>timestamp_weekday</th>\\n@@@      <th>...</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@      <th>growth_stage</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>...</td>\\n@@@      <td>False</td>\\n@@@      <td>bagel</td>\\n@@@      <td>0.085851</td>\\n@@@      <td>False</td>\\n@@@      <td>banana</td>\\n@@@      <td>0.076110</td>\\n@@@      <td>False</td>\\n@@@      <td>38492.0</td>\\n@@@      <td>8480.0</td>\\n@@@      <td>NaN</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>...</td>\\n@@@      <td>True</td>\\n@@@      <td>Pekinese</td>\\n@@@      <td>0.090647</td>\\n@@@      <td>True</td>\\n@@@      <td>papillon</td>\\n@@@      <td>0.068957</td>\\n@@@      <td>True</td>\\n@@@      <td>32986.0</td>\\n@@@      <td>6241.0</td>\\n@@@      <td>NaN</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@<p>2 rows Ã— 24 columns</p>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@#### test\\n@@@df_main.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    Int64Index: 2187 entries, 0 to 2186\\n@@@    Data columns (total 24 columns):\\n@@@    tweet_id              2187 non-null int64\\n@@@    timestamp             2187 non-null datetime64[ns]\\n@@@    source                2187 non-null category\\n@@@    text                  2187 non-null object\\n@@@    expanded_urls         2129 non-null object\\n@@@    rating_numerator      2187 non-null int64\\n@@@    rating_denominator    2187 non-null int64\\n@@@    name                  1439 non-null object\\n@@@    timestamp_month       2187 non-null int64\\n@@@    timestamp_weekday     2187 non-null int64\\n@@@    timestamp_hour        2187 non-null int64\\n@@@    jpg_url               2005 non-null object\\n@@@    p1                    2005 non-null object\\n@@@    p1_conf               2005 non-null float64\\n@@@    p1_dog                2005 non-null object\\n@@@    p2                    2005 non-null object\\n@@@    p2_conf               2005 non-null float64\\n@@@    p2_dog                2005 non-null object\\n@@@    p3                    2005 non-null object\\n@@@    p3_conf               2005 non-null float64\\n@@@    p3_dog                2005 non-null object\\n@@@    favorite_count        2186 non-null float64\\n@@@    retweet_count         2186 non-null float64\\n@@@    growth_stage          356 non-null object\\n@@@    dtypes: category(1), datetime64[ns](1), float64(5), int64(6), object(11)\\n@@@    memory usage: 412.4+ KB\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# save the main dataframe to working directory\\n@@@df_main.to_csv(\\'main_twitter_dataset.csv\\', index=False)\\n@@@```\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup for test purposes\n",
    "tmp=content_joined\n",
    "#content_joined=tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old image link\n",
    "#project_03_01_files/project_03_01_13_0.png\n",
    "\n",
    "#new image link\n",
    "#images/project_03_01_files/project_03_01_13_0.png\n",
    "\n",
    "#updated_image_link='images/'+subfolder_name+'/'+image_names[0]\n",
    "#content_joined.replace(images_folder_name+'/'+image_names[0],updated_image_link)\n",
    "\n",
    "\n",
    "#replace the image names with proper links+names\n",
    "for i in image_names:\n",
    "    #generate new links for md file\n",
    "    updated_image_link='images/'+subfolder_name+'/'+i\n",
    "    #replace the image name with proper image link\n",
    "    content_joined=content_joined.replace(images_folder_name+'/'+i,updated_image_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@@@# Wrangle Report\\n@@@\\n@@@   \\n@@@**Table of Contents**<a id=\\'Top\\'><a>   \\n@@@[Reference](#Reference)  \\n@@@[A. Data Gathering Efforts](#A)  \\n@@@[B. Data Access Issues](#B)  \\n@@@[C. Data Cleaning](#C)\\n@@@\\n@@@\\n@@@\\n@@@<a id=\\'Reference\\'></a>\\n@@@[Top](#Top)\\n@@@# Reference \\n@@@\\n@@@\\n@@@https://stackoverflow.com/questions/32400867/pandas-read-csv-from-url  \\n@@@https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object3\\n@@@https://stackoverflow.com/questions/6159900/correct-way-to-write-line-to-file\\n@@@https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file\\n@@@https://stackoverflow.com/questions/41001973/python-3-5-1-nameerror-name-json-is-not-defined\\n@@@https://stackoverflow.com/questions/27900451/convert-tweepy-status-object-into-json\\n@@@https://gist.github.com/yanofsky/5436496\\n@@@https://stackoverflow.com/questions/11716380/python-beautifulsoup-extract-text-from-anchor-tag\\n@@@https://stackoverflow.com/questions/30522724/take-multiple-lists-into-dataframe\\n@@@https://stackoverflow.com/questions/15247628/how-to-find-duplicate-names-using-pandas  \\n@@@https://stackoverflow.com/questions/466345/converting-string-into-datetime\\n@@@https://stackoverflow.com/questions/33034559/how-to-remove-last-the-two-digits-in-a-column-that-is-of-integer-type\\n@@@https://stackoverflow.com/questions/25146121/extracting-just-month-and-year-from-pandas-datetime-column-python\\n@@@https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict\\n@@@https://stackoverflow.com/questions/39092067/pandas-dataframe-convert-column-type-to-string-or-categorical\\n@@@https://stackoverflow.com/questions/18792918/combine-two-pandas-data-frames-join-on-a-common-column\\n@@@\\n@@@\\n@@@```python\\n@@@#import libraries\\n@@@import requests # reading files programmatically\\n@@@import os # manipulating file paths\\n@@@import pandas as pd\\n@@@import numpy as np\\n@@@import tweepy #read tweeter data -- pip install tweepy\\n@@@#import simplejson as json # to make json dumps --  pip install simplejson\\n@@@import json # to create json objects \\n@@@import time # to calculate the execution times of functions\\n@@@from datetime import datetime\\n@@@\\n@@@# set seed for sampling\\n@@@np.random.seed(27)\\n@@@\\n@@@```\\n@@@\\n@@@<a id=\\'A\\'></a>\\n@@@[Top](#Top)\\n@@@# A. Data Gathering Efforts \\n@@@\\n@@@## 1. Downloading the twitter-archive-enhanced.csv\\n@@@\\n@@@The twitter-archive-enhanced.csv was saved to the local directory by clicking the following link https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv \\n@@@and saving the corresponding csv file in the local working directory. \\n@@@\\n@@@\\n@@@```python\\n@@@# read the twitter-archive-enhanced.csv file intp a pandas dataframe\\n@@@df_twitter_archive=pd.read_csv(\\'twitter-archive-enhanced.csv\\')\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the dataframe\\n@@@df_twitter_archive.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 16:23:56 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 00:17:27 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the dataframe structure\\n@@@df_twitter_archive.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2356 entries, 0 to 2355\\n@@@    Data columns (total 17 columns):\\n@@@    tweet_id                      2356 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2356 non-null object\\n@@@    source                        2356 non-null object\\n@@@    text                          2356 non-null object\\n@@@    retweeted_status_id           181 non-null float64\\n@@@    retweeted_status_user_id      181 non-null float64\\n@@@    retweeted_status_timestamp    181 non-null object\\n@@@    expanded_urls                 2297 non-null object\\n@@@    rating_numerator              2356 non-null int64\\n@@@    rating_denominator            2356 non-null int64\\n@@@    name                          2356 non-null object\\n@@@    doggo                         2356 non-null object\\n@@@    floofer                       2356 non-null object\\n@@@    pupper                        2356 non-null object\\n@@@    puppo                         2356 non-null object\\n@@@    dtypes: float64(4), int64(3), object(10)\\n@@@    memory usage: 313.0+ KB\\n@@@    \\n@@@\\n@@@## Observation\\n@@@The df_twitter_archive dataframe has 17 variables and 2356 observations. Some of the variables have missing values.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@## 2. Downloading programmatically the image_predictions.tsv file\\n@@@\\n@@@The image_predictions.tsv was programmatically downloaded from https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv using the requests funciton.\\n@@@\\n@@@\\n@@@```python\\n@@@# programmatically download the image_predictions.tsv file\\n@@@url=\\'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\\'\\n@@@response=requests.get(url) # saves the file in the memory\\n@@@\\n@@@# view the file in the memory\\n@@@# response.content\\n@@@\\n@@@# create the file name by truncating the file name from the end of the url\\n@@@file_name=url.split(\\'/\\')[-1] #\\'image-predictions.tsv\\'\\n@@@\\n@@@# write the tsv file to the working directory \\n@@@with open(file_name, mode=\\'wb\\') as file:\\n@@@    file.write(response.content)\\n@@@    \\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# read the image-predictions.tsv file into a pandas file\\n@@@df_image_predictions=pd.read_csv(\\'image-predictions.tsv\\', sep = \\'\\\\t\\', encoding = \\'utf-8\\')\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the image_predictions_df dataframe\\n@@@df_image_predictions.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>img_num</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>666020888022790149</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Welsh_springer_spaniel</td>\\n@@@      <td>0.465074</td>\\n@@@      <td>True</td>\\n@@@      <td>collie</td>\\n@@@      <td>0.156665</td>\\n@@@      <td>True</td>\\n@@@      <td>Shetland_sheepdog</td>\\n@@@      <td>0.061428</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>666029285002620928</td>\\n@@@      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.506826</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.074192</td>\\n@@@      <td>True</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.072010</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the structure of the df_image_predictions dataframe\\n@@@df_image_predictions.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2075 entries, 0 to 2074\\n@@@    Data columns (total 12 columns):\\n@@@    tweet_id    2075 non-null int64\\n@@@    jpg_url     2075 non-null object\\n@@@    img_num     2075 non-null int64\\n@@@    p1          2075 non-null object\\n@@@    p1_conf     2075 non-null float64\\n@@@    p1_dog      2075 non-null bool\\n@@@    p2          2075 non-null object\\n@@@    p2_conf     2075 non-null float64\\n@@@    p2_dog      2075 non-null bool\\n@@@    p3          2075 non-null object\\n@@@    p3_conf     2075 non-null float64\\n@@@    p3_dog      2075 non-null bool\\n@@@    dtypes: bool(3), float64(3), int64(2), object(4)\\n@@@    memory usage: 152.1+ KB\\n@@@    \\n@@@\\n@@@## Observation\\n@@@\\n@@@The df_image_predictions has 12 variables and 2075 observations. The are no missing values in the dataframe.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@## 3. Downloading Twitter data via Twitter API and tweepy library\\n@@@\\n@@@\\n@@@```python\\n@@@## set tweet consumer and access key >>> replace the ### with actual keys\\n@@@consumer_key = \\'Yn71UCiC2MdIHkBalOBc08yMO\\'\\n@@@consumer_secret = \\'K7CAtE6njCkEA3trt592jJEBDRa0a6OkZsoV6MsdkM8BLWPSCl\\'\\n@@@access_token = \\'108732090-QR9V8gfQGTPu6tJBzNkINGhKjCTMh0vhuOziyoe3\\'\\n@@@access_secret = \\'HsALvm8Y5qG77fTMrfGeWjVYZY6DnupdoZu4FSBnaUmk2\\'\\n@@@\\n@@@auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\\n@@@auth.set_access_token(access_token, access_secret)\\n@@@\\n@@@# use jsonparser to make json readable content, create json dumps and query json objects\\n@@@# wait_on_rate_limit = True , allows the program to wait during timeouts \\n@@@# wait_on_rate_limit_notify = True, writes to screen when waiting\\n@@@api = tweepy.API(auth,parser=tweepy.parsers.JSONParser(),wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# function to append file line by line\\n@@@# The function was adapted from https://stackoverflow.com/questions/4706499/how-do-you-append-to-a-file\\n@@@# input: the function takes a filename string and text\\n@@@# process: the function opens a file and adds the text in append mode\\n@@@# out: none\\n@@@def FileSave(filename,content):\\n@@@    with open(filename, \"a\") as myfile:\\n@@@        myfile.write(content)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# input: the function takes a list of tweet ids and a filename\\n@@@# process: the function downloads tweets corresponding to a tweet ids and adds it to a file\\n@@@# out: the function prints out the time taken to download the tweets, prints the error msgs and\\n@@@#      returns a list of ids that could not be downloaded\\n@@@\\n@@@def download_tweets(id_list,filename):\\n@@@    \\n@@@    # set the start time\\n@@@    start_time = time.time()\\n@@@\\n@@@    unloaded_tweet_ids=[]\\n@@@    counter=0\\n@@@    for i in id_list:\\n@@@        try:\\n@@@            #print(counter,\\' >> Tweet id: \\',i)\\n@@@            tweet=api.get_status(i,tweet_mode=\\'extended\\')\\n@@@            FileSave(filename,json.dumps(tweet)+\\'\\\\n\\')\\n@@@            counter=counter+1\\n@@@            \\n@@@        except Exception as download_error_msg:\\n@@@            print(counter,\\' >> Tweet id: \\',i)\\n@@@            print(download_error_msg)\\n@@@            unloaded_tweet_ids.append(i)\\n@@@            counter=counter+1\\n@@@\\n@@@            \\n@@@    #print unloaded tweeter ids\\n@@@    print(\\'\\\\n \\\\nTotal number of Tweeter ids :\\',len(id_list))\\n@@@    print(\\'The following \\',len(unloaded_tweet_ids), \\'tweet ids could not be downloaded for various reasons: \\')\\n@@@    print(unloaded_tweet_ids)\\n@@@    \\n@@@    # set the end time\\n@@@    end_time = time.time()\\n@@@\\n@@@    # print the execution time\\n@@@    print(\\'\\\\n \\\\nThe download process took: \\', (end_time - start_time)/60, \\' minutes\\')\\n@@@    \\n@@@    return(unloaded_tweet_ids)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# set the tweet ids that will be using in the api to access the actual data\\n@@@tweet_id=df_twitter_archive[\\'tweet_id\\']\\n@@@\\n@@@# download tweets by passing the tweet_id list and tweet_json.txt filename\\n@@@# save the results of unloaded ids so they can be attempted again\\n@@@error_ids_01=download_tweets(tweet_id,\\'tweet_json.txt\\')\\n@@@```\\n@@@\\n@@@    19  >> Tweet id:  888202515573088257\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    95  >> Tweet id:  873697596434513921\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    118  >> Tweet id:  869988702071779329\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    132  >> Tweet id:  866816280283807744\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    155  >> Tweet id:  861769973181624320\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    247  >> Tweet id:  845459076796616705\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    260  >> Tweet id:  842892208864923648\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    298  >> Tweet id:  837012587749474308\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    382  >> Tweet id:  827228250799742977\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    566  >> Tweet id:  802247111496568832\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    784  >> Tweet id:  775096608509886464\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    815  >> Tweet id:  771004394259247104\\n@@@    [{\\'code\\': 179, \\'message\\': \\'Sorry, you are not authorized to see this status.\\'}]\\n@@@    818  >> Tweet id:  770743923962707968\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    \\n@@@\\n@@@    Rate limit reached. Sleeping for: 732\\n@@@    \\n@@@\\n@@@    932  >> Tweet id:  754011816964026368\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    \\n@@@\\n@@@    Rate limit reached. Sleeping for: 728\\n@@@    \\n@@@\\n@@@    \\n@@@     \\n@@@    Total number of Tweeter ids : 2356\\n@@@    The following  14 tweet ids could not be downloaded for various reasons: \\n@@@    [888202515573088257, 873697596434513921, 869988702071779329, 866816280283807744, 861769973181624320, 845459076796616705, 842892208864923648, 837012587749474308, 827228250799742977, 802247111496568832, 775096608509886464, 771004394259247104, 770743923962707968, 754011816964026368]\\n@@@    \\n@@@     \\n@@@    The download process took:  31.737418989340465  minutes\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# try to download the tweet contents corresponding the error tweets\\n@@@error_ids_02=download_tweets(error_ids_01,\\'tweet_json.txt\\')\\n@@@```\\n@@@\\n@@@    0  >> Tweet id:  888202515573088257\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    1  >> Tweet id:  873697596434513921\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    2  >> Tweet id:  869988702071779329\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    3  >> Tweet id:  866816280283807744\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    4  >> Tweet id:  861769973181624320\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    5  >> Tweet id:  845459076796616705\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    6  >> Tweet id:  842892208864923648\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    7  >> Tweet id:  837012587749474308\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    8  >> Tweet id:  827228250799742977\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    9  >> Tweet id:  802247111496568832\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    10  >> Tweet id:  775096608509886464\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    11  >> Tweet id:  771004394259247104\\n@@@    [{\\'code\\': 179, \\'message\\': \\'Sorry, you are not authorized to see this status.\\'}]\\n@@@    12  >> Tweet id:  770743923962707968\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    13  >> Tweet id:  754011816964026368\\n@@@    [{\\'code\\': 144, \\'message\\': \\'No status found with that ID.\\'}]\\n@@@    \\n@@@     \\n@@@    Total number of Tweeter ids : 14\\n@@@    The following  14 tweet ids could not be downloaded for various reasons: \\n@@@    [888202515573088257, 873697596434513921, 869988702071779329, 866816280283807744, 861769973181624320, 845459076796616705, 842892208864923648, 837012587749474308, 827228250799742977, 802247111496568832, 775096608509886464, 771004394259247104, 770743923962707968, 754011816964026368]\\n@@@    \\n@@@     \\n@@@    The download process took:  0.03408433596293132  minutes\\n@@@    \\n@@@\\n@@@## Observation\\n@@@\\n@@@At this point, we have successfully saved each tweet\\'s entire content in a tweet_json.txt file with each tweet in a new line.There were 13 tweets that could not be downloaded for various reasons.  \\n@@@\\n@@@Next, we will read the file into memory where each tweet will be saved into a separate element in a list called \\'lines\\'. We will then iterate through the lines list and extract interesting elements such as tweet text, favourites count, retweet count etc in separate lists and later concatenate the lists into a dataframe.  \\n@@@\\n@@@\\n@@@```python\\n@@@## read json file to a list array and strip new line charactor\\n@@@lines = [line.rstrip(\\'\\\\n\\') for line in open(\\'tweet_json.txt\\')]\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# read one tweet into a temp file to examine its content\\n@@@# load the tweet into a json format for easier extraction of information\\n@@@tmp = json.loads(lines[0])\\n@@@\\n@@@# examine a tweet\\n@@@tmp\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    {\\'contributors\\': None,\\n@@@     \\'coordinates\\': None,\\n@@@     \\'created_at\\': \\'Tue Aug 01 16:23:56 +0000 2017\\',\\n@@@     \\'display_text_range\\': [0, 85],\\n@@@     \\'entities\\': {\\'hashtags\\': [],\\n@@@      \\'media\\': [{\\'display_url\\': \\'pic.twitter.com/MgUWQ76dJU\\',\\n@@@        \\'expanded_url\\': \\'https://twitter.com/dog_rates/status/892420643555336193/photo/1\\',\\n@@@        \\'id\\': 892420639486877696,\\n@@@        \\'id_str\\': \\'892420639486877696\\',\\n@@@        \\'indices\\': [86, 109],\\n@@@        \\'media_url\\': \\'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'media_url_https\\': \\'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'sizes\\': {\\'large\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'medium\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'small\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'thumb\\': {\\'h\\': 150, \\'resize\\': \\'crop\\', \\'w\\': 150}},\\n@@@        \\'type\\': \\'photo\\',\\n@@@        \\'url\\': \\'https://t.co/MgUWQ76dJU\\'}],\\n@@@      \\'symbols\\': [],\\n@@@      \\'urls\\': [],\\n@@@      \\'user_mentions\\': []},\\n@@@     \\'extended_entities\\': {\\'media\\': [{\\'display_url\\': \\'pic.twitter.com/MgUWQ76dJU\\',\\n@@@        \\'expanded_url\\': \\'https://twitter.com/dog_rates/status/892420643555336193/photo/1\\',\\n@@@        \\'id\\': 892420639486877696,\\n@@@        \\'id_str\\': \\'892420639486877696\\',\\n@@@        \\'indices\\': [86, 109],\\n@@@        \\'media_url\\': \\'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'media_url_https\\': \\'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg\\',\\n@@@        \\'sizes\\': {\\'large\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'medium\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'small\\': {\\'h\\': 528, \\'resize\\': \\'fit\\', \\'w\\': 540},\\n@@@         \\'thumb\\': {\\'h\\': 150, \\'resize\\': \\'crop\\', \\'w\\': 150}},\\n@@@        \\'type\\': \\'photo\\',\\n@@@        \\'url\\': \\'https://t.co/MgUWQ76dJU\\'}]},\\n@@@     \\'favorite_count\\': 38492,\\n@@@     \\'favorited\\': False,\\n@@@     \\'full_text\\': \"This is Phineas. He\\'s a mystical boy. Only ever appears in the hole of a donut. 13/10 https://t.co/MgUWQ76dJU\",\\n@@@     \\'geo\\': None,\\n@@@     \\'id\\': 892420643555336193,\\n@@@     \\'id_str\\': \\'892420643555336193\\',\\n@@@     \\'in_reply_to_screen_name\\': None,\\n@@@     \\'in_reply_to_status_id\\': None,\\n@@@     \\'in_reply_to_status_id_str\\': None,\\n@@@     \\'in_reply_to_user_id\\': None,\\n@@@     \\'in_reply_to_user_id_str\\': None,\\n@@@     \\'is_quote_status\\': False,\\n@@@     \\'lang\\': \\'en\\',\\n@@@     \\'place\\': None,\\n@@@     \\'possibly_sensitive\\': False,\\n@@@     \\'possibly_sensitive_appealable\\': False,\\n@@@     \\'retweet_count\\': 8480,\\n@@@     \\'retweeted\\': False,\\n@@@     \\'source\\': \\'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\\',\\n@@@     \\'truncated\\': False,\\n@@@     \\'user\\': {\\'contributors_enabled\\': False,\\n@@@      \\'created_at\\': \\'Sun Nov 15 21:41:29 +0000 2015\\',\\n@@@      \\'default_profile\\': False,\\n@@@      \\'default_profile_image\\': False,\\n@@@      \\'description\\': \\'Your Only Source For Professional Dog Ratings  IG, FB, Snapchat â‡¨ WeRateDogs â\\xa0€â\\xa0€â\\xa0€â\\xa0€ Business Inquiries: dogratingtwitter@gmail.com\\',\\n@@@      \\'entities\\': {\\'description\\': {\\'urls\\': []},\\n@@@       \\'url\\': {\\'urls\\': [{\\'display_url\\': \\'weratedogs.com\\',\\n@@@          \\'expanded_url\\': \\'http://weratedogs.com\\',\\n@@@          \\'indices\\': [0, 23],\\n@@@          \\'url\\': \\'https://t.co/N7sNNHAEXS\\'}]}},\\n@@@      \\'favourites_count\\': 137074,\\n@@@      \\'follow_request_sent\\': False,\\n@@@      \\'followers_count\\': 7174950,\\n@@@      \\'following\\': False,\\n@@@      \\'friends_count\\': 10,\\n@@@      \\'geo_enabled\\': True,\\n@@@      \\'has_extended_profile\\': False,\\n@@@      \\'id\\': 4196983835,\\n@@@      \\'id_str\\': \\'4196983835\\',\\n@@@      \\'is_translation_enabled\\': False,\\n@@@      \\'is_translator\\': False,\\n@@@      \\'lang\\': \\'en\\',\\n@@@      \\'listed_count\\': 4906,\\n@@@      \\'location\\': \\'â‡© merch â‡©         DM YOUR DOGS\\',\\n@@@      \\'name\\': \\'WeRateDogsâ„¢\\',\\n@@@      \\'notifications\\': False,\\n@@@      \\'profile_background_color\\': \\'000000\\',\\n@@@      \\'profile_background_image_url\\': \\'http://abs.twimg.com/images/themes/theme1/bg.png\\',\\n@@@      \\'profile_background_image_url_https\\': \\'https://abs.twimg.com/images/themes/theme1/bg.png\\',\\n@@@      \\'profile_background_tile\\': False,\\n@@@      \\'profile_banner_url\\': \\'https://pbs.twimg.com/profile_banners/4196983835/1525830435\\',\\n@@@      \\'profile_image_url\\': \\'http://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg\\',\\n@@@      \\'profile_image_url_https\\': \\'https://pbs.twimg.com/profile_images/948761950363664385/Fpr2Oz35_normal.jpg\\',\\n@@@      \\'profile_link_color\\': \\'F5ABB5\\',\\n@@@      \\'profile_sidebar_border_color\\': \\'000000\\',\\n@@@      \\'profile_sidebar_fill_color\\': \\'000000\\',\\n@@@      \\'profile_text_color\\': \\'000000\\',\\n@@@      \\'profile_use_background_image\\': False,\\n@@@      \\'protected\\': False,\\n@@@      \\'screen_name\\': \\'dog_rates\\',\\n@@@      \\'statuses_count\\': 8670,\\n@@@      \\'time_zone\\': None,\\n@@@      \\'translator_type\\': \\'none\\',\\n@@@      \\'url\\': \\'https://t.co/N7sNNHAEXS\\',\\n@@@      \\'utc_offset\\': None,\\n@@@      \\'verified\\': True}}\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# Extract elements\\n@@@print(tmp[\\'id\\'])\\n@@@```\\n@@@\\n@@@    892420643555336193\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# Extract elements from the lines list\\n@@@\\n@@@# total number of tweets \\n@@@number_of_tweets=len(lines)\\n@@@\\n@@@# initialize a set of lists that will hold informative tweet elements \\n@@@list_t_ids=[] # will store ids\\n@@@list_t_created_at=[] # will store the dates tweets were created \\n@@@list_t_full_text=[] # will store the full text\\n@@@list_t_favorite_count=[] # will store the count of favorites\\n@@@list_t_retweet_count=[] # will store the count of retweets\\n@@@\\n@@@# iterate over the lines list of tweets, extract information and save to the initialized lists\\n@@@for i in range(number_of_tweets):\\n@@@    \\n@@@    # load a list element containing a tweet into json format\\n@@@    tmp = json.loads(lines[i])\\n@@@    \\n@@@    # extract and add the id\\n@@@    list_t_ids.append(tmp[\\'id\\'])\\n@@@\\n@@@    # extract and add the date the tweet was created\\n@@@    list_t_created_at.append(tmp[\\'created_at\\'])\\n@@@\\n@@@    \\n@@@    # extract and add the full text from the tweet\\n@@@    list_t_full_text.append(tmp[\\'full_text\\'])\\n@@@    \\n@@@    # extract add the favorite count\\n@@@    list_t_favorite_count.append(tmp[\\'favorite_count\\'])\\n@@@    \\n@@@    # extract and add the retweet count\\n@@@    list_t_retweet_count.append(tmp[\\'retweet_count\\'])\\n@@@        \\n@@@    #print(i)\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# concatenate the lists into a pandas dataframe\\n@@@lists = [list_t_ids, list_t_created_at, list_t_full_text,list_t_favorite_count,list_t_retweet_count]\\n@@@df_json_tweets = pd.concat([pd.Series(x) for x in lists], axis=1)\\n@@@df_json_tweets.columns = [\\'tweet_id\\', \\'time_created\\',\\'full_text\\',\\'favorite_count\\',\\'retweet_count\\']\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the jason_tweets dataframe\\n@@@df_json_tweets.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>time_created</th>\\n@@@      <th>full_text</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>Tue Aug 01 16:23:56 +0000 2017</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>38492</td>\\n@@@      <td>8480</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>Tue Aug 01 00:17:27 +0000 2017</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>32986</td>\\n@@@      <td>6241</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>Mon Jul 31 00:18:03 +0000 2017</td>\\n@@@      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\\n@@@      <td>24840</td>\\n@@@      <td>4137</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>Sun Jul 30 15:58:51 +0000 2017</td>\\n@@@      <td>This is Darla. She commenced a snooze mid meal...</td>\\n@@@      <td>41865</td>\\n@@@      <td>8598</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>Sat Jul 29 16:00:24 +0000 2017</td>\\n@@@      <td>This is Franklin. He would like you to stop ca...</td>\\n@@@      <td>40029</td>\\n@@@      <td>9336</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# examine the json_tweets data structure\\n@@@df_json_tweets.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2342 entries, 0 to 2341\\n@@@    Data columns (total 5 columns):\\n@@@    tweet_id          2342 non-null int64\\n@@@    time_created      2342 non-null object\\n@@@    full_text         2342 non-null object\\n@@@    favorite_count    2342 non-null int64\\n@@@    retweet_count     2342 non-null int64\\n@@@    dtypes: int64(3), object(2)\\n@@@    memory usage: 91.6+ KB\\n@@@    \\n@@@\\n@@@## Observation\\n@@@\\n@@@df_json_tweets dataframe has 5 variables and 2343 observations. It has no missing values.\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@<a id=\\'B\\'></a>\\n@@@[Top](#Top)\\n@@@## B. Data Access Issues \\n@@@(The insights here are summarized from analysis in this subsection.)\\n@@@\\n@@@\\n@@@## Content Issues \\n@@@\\n@@@(Visual & Programmatically - completness, validity, accuracy, consistency)\\n@@@\\n@@@### twitter_archive dataframe\\n@@@    \\n@@@    - The expanded_url column, has some instances where the url is repeated multiple times in a cell separated by a comma\\n@@@    - The name column has non name strings such as None, a, an \\n@@@    - Rating_denominator as high as 80\\n@@@    - The following variables should be integers instead of floats: in_reply_to_status_id,in_reply_to_user_id,    \\n@@@      retweeted_status_id,retweeted_status_user_id \\n@@@    - Contains retweets\\n@@@\\n@@@\\n@@@### image_predictions dataframe\\n@@@\\n@@@    - p1, p2,p3: upper and lower case mixed together\\n@@@    - p1, p2,p3: dash and underscore mixed in string eg. black-and-tan_coonhound\\t\\n@@@    - Missing values when compared to twitter_archive dataframe\\n@@@\\n@@@###  tweet_json dataframe\\n@@@\\n@@@    - time_created should be a data/time object\\n@@@\\n@@@## Structural Issues\\n@@@\\n@@@(Visual & Programmatically -  variable(column), observation(row), unit(table))\\n@@@\\n@@@### twitter_archive dataframe\\n@@@\\n@@@    - The timestamp column contains two separate variables date and time. \\n@@@    - The anchor text in source column is repeated numerous times\\n@@@    - Variables called \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\' are different growth stages of a pet based on age.\\n@@@\\n@@@### image_predictions dataframe\\n@@@\\n@@@    - Merge the dataset with twitter_archive dataframe based on tweet_id\\n@@@\\n@@@###  tweet_json dataframe\\n@@@\\n@@@    - time_created could be further split into day, month and time \\n@@@    - Merge this dataframe with twitter_archive dataframe\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# function to find duplicates in a dataframe column\\n@@@# source:  https://stackoverflow.com/questions/15247628/how-to-find-duplicate-names-using-pandas\\n@@@def find_duplicates(df_column):\\n@@@    names=df_column.value_counts()\\n@@@    return(names[names>1])\\n@@@```\\n@@@\\n@@@# Analysing the twitter_archive dataframe\\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 16:23:56 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 00:17:27 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@There is presence of missing values in twitter archive table so this needs to be further investigated. The timestamp column contains two separate variables date and time. \\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.columns\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Index([\\'tweet_id\\', \\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'timestamp\\',\\n@@@           \\'source\\', \\'text\\', \\'retweeted_status_id\\', \\'retweeted_status_user_id\\',\\n@@@           \\'retweeted_status_timestamp\\', \\'expanded_urls\\', \\'rating_numerator\\',\\n@@@           \\'rating_denominator\\', \\'name\\', \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\'],\\n@@@          dtype=\\'object\\')\\n@@@\\n@@@\\n@@@\\n@@@Variables called \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\' are different growth stages of a pet and should be in one column.\\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.sample(5)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>815</th>\\n@@@      <td>771004394259247104</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2016-08-31 15:19:06 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>RT @katieornah: @dog_rates learning a lot at c...</td>\\n@@@      <td>7.710021e+17</td>\\n@@@      <td>1.732729e+09</td>\\n@@@      <td>2016-08-31 15:10:07 +0000</td>\\n@@@      <td>https://twitter.com/katieornah/status/77100213...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>pupper</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>682</th>\\n@@@      <td>788552643979468800</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2016-10-19 01:29:35 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>RT @dog_rates: Say hello to mad pupper. You kn...</td>\\n@@@      <td>7.363926e+17</td>\\n@@@      <td>4.196984e+09</td>\\n@@@      <td>2016-05-28 03:04:00 +0000</td>\\n@@@      <td>https://vine.co/v/iEggaEOiLO3,https://vine.co/...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>mad</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>pupper</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>254</th>\\n@@@      <td>844580511645339650</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-03-22 16:04:20 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Charlie. He wants to know if you have ...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/844580511...</td>\\n@@@      <td>11</td>\\n@@@      <td>10</td>\\n@@@      <td>Charlie</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>741</th>\\n@@@      <td>780496263422808064</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2016-09-26 19:56:24 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>RT @dog_rates: This is Bell. She likes holding...</td>\\n@@@      <td>7.424232e+17</td>\\n@@@      <td>4.196984e+09</td>\\n@@@      <td>2016-06-13 18:27:32 +0000</td>\\n@@@      <td>https://twitter.com/dog_rates/status/742423170...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>Bell</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>143</th>\\n@@@      <td>864197398364647424</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-05-15 19:14:50 +0000</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Paisley. She ate a flower just to prov...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/864197398...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Paisley</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.tweet_id)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: tweet_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@no duplicates in tweet id\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.source)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>     2221\\n@@@    <a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                          91\\n@@@    <a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                       33\\n@@@    <a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>      11\\n@@@    Name: source, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@the anchor text in source column is repeated numerous times - good candidate for categorical object\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.expanded_urls).head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    https://twitter.com/dog_rates/status/829501995190984704/photo/1,https://twitter.com/dog_rates/status/829501995190984704/photo/1    2\\n@@@    https://twitter.com/dog_rates/status/819227688460238848/photo/1                                                                    2\\n@@@    https://twitter.com/dog_rates/status/683391852557561860/photo/1                                                                    2\\n@@@    https://twitter.com/dog_rates/status/832369877331693569/photo/1                                                                    2\\n@@@    https://twitter.com/dog_rates/status/753375668877008896/photo/1                                                                    2\\n@@@    Name: expanded_urls, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@In the expanded_url column, there some instances where the url is repeated multiple times in a cell separated by a comma\\n@@@eg. https://twitter.com/dog_rates/status/791406955684368384/photo/1,https://twitter.com/dog_rates/status/791406955684368384/photo/1,https://twitter.com/dog_rates/status/791406955684368384/photo/1,https://twitter.com/dog_rates/status/791406955684368384/photo/1 -- may consider removing the repeated link after the comma \\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_numerator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    12     558\\n@@@    11     464\\n@@@    10     461\\n@@@    13     351\\n@@@    9      158\\n@@@    8      102\\n@@@    7       55\\n@@@    14      54\\n@@@    5       37\\n@@@    6       32\\n@@@    3       19\\n@@@    4       17\\n@@@    1        9\\n@@@    2        9\\n@@@    420      2\\n@@@    0        2\\n@@@    15       2\\n@@@    75       2\\n@@@    Name: rating_numerator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_denominator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    10    2333\\n@@@    11       3\\n@@@    50       3\\n@@@    80       2\\n@@@    20       2\\n@@@    Name: rating_denominator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.name).head(20)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    None       745\\n@@@    a           55\\n@@@    Charlie     12\\n@@@    Lucy        11\\n@@@    Oliver      11\\n@@@    Cooper      11\\n@@@    Penny       10\\n@@@    Tucker      10\\n@@@    Lola        10\\n@@@    Winston      9\\n@@@    Bo           9\\n@@@    Sadie        8\\n@@@    the          8\\n@@@    Toby         7\\n@@@    Bailey       7\\n@@@    Buddy        7\\n@@@    an           7\\n@@@    Daisy        7\\n@@@    Stanley      6\\n@@@    Koda         6\\n@@@    Name: name, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@The name column has non name strings such as None, a, an.  \\n@@@Could conside replacing non-name strings with nan.\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_numerator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    12     558\\n@@@    11     464\\n@@@    10     461\\n@@@    13     351\\n@@@    9      158\\n@@@    8      102\\n@@@    7       55\\n@@@    14      54\\n@@@    5       37\\n@@@    6       32\\n@@@    3       19\\n@@@    4       17\\n@@@    1        9\\n@@@    2        9\\n@@@    420      2\\n@@@    0        2\\n@@@    15       2\\n@@@    75       2\\n@@@    Name: rating_numerator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@Interesting to note that rating number of 420 occurs twice and it seems too \\'high - 420\\'. \\n@@@Instructions indicate that rating_numerator is almost more than 10. Also, interesting to note that there are 9 occurances of rating of 1 and 2.\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_twitter_archive.rating_denominator)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    10    2333\\n@@@    11       3\\n@@@    50       3\\n@@@    80       2\\n@@@    20       2\\n@@@    Name: rating_denominator, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@According to instructions, the denominator should be 10. But denominators as high as 80 can be observed.\\n@@@May consider changing them to 10.\\n@@@\\n@@@\\n@@@```python\\n@@@df_twitter_archive.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2356 entries, 0 to 2355\\n@@@    Data columns (total 17 columns):\\n@@@    tweet_id                      2356 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2356 non-null object\\n@@@    source                        2356 non-null object\\n@@@    text                          2356 non-null object\\n@@@    retweeted_status_id           181 non-null float64\\n@@@    retweeted_status_user_id      181 non-null float64\\n@@@    retweeted_status_timestamp    181 non-null object\\n@@@    expanded_urls                 2297 non-null object\\n@@@    rating_numerator              2356 non-null int64\\n@@@    rating_denominator            2356 non-null int64\\n@@@    name                          2356 non-null object\\n@@@    doggo                         2356 non-null object\\n@@@    floofer                       2356 non-null object\\n@@@    pupper                        2356 non-null object\\n@@@    puppo                         2356 non-null object\\n@@@    dtypes: float64(4), int64(3), object(10)\\n@@@    memory usage: 313.0+ KB\\n@@@    \\n@@@\\n@@@The table has 17 variables and 2356 observations. The table is organized by 2356 unique tweet_ids.\\n@@@\\n@@@There is presence of missing values in in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, \\n@@@retweeted_status_user_id,retweeted_status_timestamp, expanded_urls.\\n@@@\\n@@@The following variables should be integers instead of floats: in_reply_to_status_id,in_reply_to_user_id, retweeted_status_id,retweeted_status_user_id.  \\n@@@\\n@@@Timestamp is a string object instead of a date time object.\\n@@@\\n@@@retweeted_status_id count of 181 indicates that there are 181 tweets that are actually retweets and will need to be removed from the dataframe as we will be only working with original tweets and not retweets.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@# Analysing the image_predictions dataframe\\n@@@\\n@@@\\n@@@```python\\n@@@df_image_predictions.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>img_num</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>666020888022790149</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Welsh_springer_spaniel</td>\\n@@@      <td>0.465074</td>\\n@@@      <td>True</td>\\n@@@      <td>collie</td>\\n@@@      <td>0.156665</td>\\n@@@      <td>True</td>\\n@@@      <td>Shetland_sheepdog</td>\\n@@@      <td>0.061428</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>666029285002620928</td>\\n@@@      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.506826</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.074192</td>\\n@@@      <td>True</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.072010</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>666033412701032449</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>German_shepherd</td>\\n@@@      <td>0.596461</td>\\n@@@      <td>True</td>\\n@@@      <td>malinois</td>\\n@@@      <td>0.138584</td>\\n@@@      <td>True</td>\\n@@@      <td>bloodhound</td>\\n@@@      <td>0.116197</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>666044226329800704</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.408143</td>\\n@@@      <td>True</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.360687</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.222752</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>666049248165822465</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.560311</td>\\n@@@      <td>True</td>\\n@@@      <td>Rottweiler</td>\\n@@@      <td>0.243682</td>\\n@@@      <td>True</td>\\n@@@      <td>Doberman</td>\\n@@@      <td>0.154629</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@p1, p2,p3: upper and lower case mixed together\\n@@@\\n@@@\\n@@@```python\\n@@@df_image_predictions.sample(5)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>img_num</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>892</th>\\n@@@      <td>699413908797464576</td>\\n@@@      <td>https://pbs.twimg.com/media/CbTRPXdW8AQMZf7.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Samoyed</td>\\n@@@      <td>0.517479</td>\\n@@@      <td>True</td>\\n@@@      <td>malamute</td>\\n@@@      <td>0.155935</td>\\n@@@      <td>True</td>\\n@@@      <td>Eskimo_dog</td>\\n@@@      <td>0.095001</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1967</th>\\n@@@      <td>867900495410671616</td>\\n@@@      <td>https://pbs.twimg.com/media/DAtm5MkXoAA4R6P.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Labrador_retriever</td>\\n@@@      <td>0.522644</td>\\n@@@      <td>True</td>\\n@@@      <td>kuvasz</td>\\n@@@      <td>0.332461</td>\\n@@@      <td>True</td>\\n@@@      <td>dalmatian</td>\\n@@@      <td>0.032008</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1397</th>\\n@@@      <td>768193404517830656</td>\\n@@@      <td>https://pbs.twimg.com/media/Cqkr0wiW8AAn2Oi.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>lion</td>\\n@@@      <td>0.396984</td>\\n@@@      <td>False</td>\\n@@@      <td>ram</td>\\n@@@      <td>0.300851</td>\\n@@@      <td>False</td>\\n@@@      <td>cheetah</td>\\n@@@      <td>0.094474</td>\\n@@@      <td>False</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>771</th>\\n@@@      <td>689517482558820352</td>\\n@@@      <td>https://pbs.twimg.com/media/CZGofjJW0AINjN9.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>Pembroke</td>\\n@@@      <td>0.799319</td>\\n@@@      <td>True</td>\\n@@@      <td>Cardigan</td>\\n@@@      <td>0.189537</td>\\n@@@      <td>True</td>\\n@@@      <td>papillon</td>\\n@@@      <td>0.003386</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>919</th>\\n@@@      <td>701889187134500865</td>\\n@@@      <td>https://pbs.twimg.com/media/Cb2cfd9WAAEL-zk.jpg</td>\\n@@@      <td>1</td>\\n@@@      <td>French_bulldog</td>\\n@@@      <td>0.902856</td>\\n@@@      <td>True</td>\\n@@@      <td>Staffordshire_bullterrier</td>\\n@@@      <td>0.022634</td>\\n@@@      <td>True</td>\\n@@@      <td>soap_dispenser</td>\\n@@@      <td>0.011973</td>\\n@@@      <td>False</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@p1, p2,p3: dash and underscore mixed in string eg. black-and-tan_coonhound\\t\\n@@@\\n@@@\\n@@@```python\\n@@@df_image_predictions.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2075 entries, 0 to 2074\\n@@@    Data columns (total 12 columns):\\n@@@    tweet_id    2075 non-null int64\\n@@@    jpg_url     2075 non-null object\\n@@@    img_num     2075 non-null int64\\n@@@    p1          2075 non-null object\\n@@@    p1_conf     2075 non-null float64\\n@@@    p1_dog      2075 non-null bool\\n@@@    p2          2075 non-null object\\n@@@    p2_conf     2075 non-null float64\\n@@@    p2_dog      2075 non-null bool\\n@@@    p3          2075 non-null object\\n@@@    p3_conf     2075 non-null float64\\n@@@    p3_dog      2075 non-null bool\\n@@@    dtypes: bool(3), float64(3), int64(2), object(4)\\n@@@    memory usage: 152.1+ KB\\n@@@    \\n@@@\\n@@@No missing values in this dataset.\\n@@@\\n@@@This dataset should be merged with the archived dataset based on the tweet ids becuase this dataset is predicting the images of the tweet ids. In that case, this dataset will have missing values as the archive dataset has 2355 observations and this dataset\\n@@@has 2075 instances.\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_image_predictions.tweet_id)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: tweet_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@no duplicates in tweet id\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_image_predictions.jpg_url).head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    https://pbs.twimg.com/ext_tw_video_thumb/675354114423808004/pu/img/qL1R_nGLqa6lmkOx.jpg    2\\n@@@    https://pbs.twimg.com/media/DA7iHL5U0AA1OQo.jpg                                            2\\n@@@    https://pbs.twimg.com/media/CYLDikFWEAAIy1y.jpg                                            2\\n@@@    https://pbs.twimg.com/media/CzG425nWgAAnP7P.jpg                                            2\\n@@@    https://pbs.twimg.com/media/CkjMx99UoAM2B1a.jpg                                            2\\n@@@    Name: jpg_url, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@numerous urls are repeated in the jpg_url column - this could or could not be an issue in future\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@# Analysing the tweet_json dataframe\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>time_created</th>\\n@@@      <th>full_text</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>Tue Aug 01 16:23:56 +0000 2017</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>38492</td>\\n@@@      <td>8480</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>Tue Aug 01 00:17:27 +0000 2017</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>32986</td>\\n@@@      <td>6241</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>Mon Jul 31 00:18:03 +0000 2017</td>\\n@@@      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\\n@@@      <td>24840</td>\\n@@@      <td>4137</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>Sun Jul 30 15:58:51 +0000 2017</td>\\n@@@      <td>This is Darla. She commenced a snooze mid meal...</td>\\n@@@      <td>41865</td>\\n@@@      <td>8598</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>Sat Jul 29 16:00:24 +0000 2017</td>\\n@@@      <td>This is Franklin. He would like you to stop ca...</td>\\n@@@      <td>40029</td>\\n@@@      <td>9336</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@time_created could be further split into day, month and time.\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.sample(5)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>time_created</th>\\n@@@      <th>full_text</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>2069</th>\\n@@@      <td>670811965569282048</td>\\n@@@      <td>Sun Nov 29 03:50:10 +0000 2015</td>\\n@@@      <td>Meet Maggie. She enjoys her stick in the yard....</td>\\n@@@      <td>1162</td>\\n@@@      <td>281</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2227</th>\\n@@@      <td>667915453470232577</td>\\n@@@      <td>Sat Nov 21 04:00:28 +0000 2015</td>\\n@@@      <td>Meet Otis. He is a Peruvian Quartzite. Pic spo...</td>\\n@@@      <td>216</td>\\n@@@      <td>58</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1886</th>\\n@@@      <td>674664755118911488</td>\\n@@@      <td>Wed Dec 09 18:59:46 +0000 2015</td>\\n@@@      <td>This is Rodman. He\\'s getting destroyed by the ...</td>\\n@@@      <td>957</td>\\n@@@      <td>270</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1339</th>\\n@@@      <td>703769065844768768</td>\\n@@@      <td>Sun Feb 28 02:29:55 +0000 2016</td>\\n@@@      <td>When you\\'re trying to watch your favorite tv s...</td>\\n@@@      <td>3494</td>\\n@@@      <td>1231</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1974</th>\\n@@@      <td>672834301050937345</td>\\n@@@      <td>Fri Dec 04 17:46:12 +0000 2015</td>\\n@@@      <td>This is Ed. He\\'s not mad, just disappointed. 1...</td>\\n@@@      <td>1352</td>\\n@@@      <td>595</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.describe()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>count</th>\\n@@@      <td>2.342000e+03</td>\\n@@@      <td>2342.000000</td>\\n@@@      <td>2342.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>mean</th>\\n@@@      <td>7.422646e+17</td>\\n@@@      <td>8042.367635</td>\\n@@@      <td>2980.833049</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>std</th>\\n@@@      <td>6.837466e+16</td>\\n@@@      <td>12364.650672</td>\\n@@@      <td>4990.628083</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>min</th>\\n@@@      <td>6.660209e+17</td>\\n@@@      <td>0.000000</td>\\n@@@      <td>0.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>25%</th>\\n@@@      <td>6.783509e+17</td>\\n@@@      <td>1394.250000</td>\\n@@@      <td>599.250000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>50%</th>\\n@@@      <td>7.186224e+17</td>\\n@@@      <td>3509.000000</td>\\n@@@      <td>1395.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>75%</th>\\n@@@      <td>7.987010e+17</td>\\n@@@      <td>9881.750000</td>\\n@@@      <td>3478.000000</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>max</th>\\n@@@      <td>8.924206e+17</td>\\n@@@      <td>162143.000000</td>\\n@@@      <td>84152.000000</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@There is a tweet that got 142,306 favorite counts and 76,667 retweet counts. It would be nice to investigate this further in visuals to see if it is the same tweet. Also what days do most tweets occur?\\n@@@\\n@@@\\n@@@```python\\n@@@find_duplicates(df_json_tweets.tweet_id)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: tweet_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@tweet_id is not duplicated.\\n@@@\\n@@@\\n@@@```python\\n@@@df_json_tweets.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2342 entries, 0 to 2341\\n@@@    Data columns (total 5 columns):\\n@@@    tweet_id          2342 non-null int64\\n@@@    time_created      2342 non-null object\\n@@@    full_text         2342 non-null object\\n@@@    favorite_count    2342 non-null int64\\n@@@    retweet_count     2342 non-null int64\\n@@@    dtypes: int64(3), object(2)\\n@@@    memory usage: 91.6+ KB\\n@@@    \\n@@@\\n@@@Since this dataframe\\'s tweet id is based on the tweet id of the twitter_archive dataframe\\'s tweet id, we can merge both these\\n@@@tables into one table and add the favorite_count annd retweet_count from json_tweets dataframe to twitter_archive dataframe.\\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@<a id=\\'C\\'></a>\\n@@@[Top](#Top)\\n@@@# C. Data Cleaning \\n@@@(Define, code, test )\\n@@@- code and test are addressed separately for each issue.\\n@@@\\n@@@### Define - Content Issues\\n@@@#### Cleaning the twitter_archive dataframe \\n@@@\\n@@@1. Format the timestamp to datetime format\\n@@@2. Add columns for the month, weekday and hour the tweet was created\\n@@@3. Remove all retweets\\n@@@4. Convert source to categorical value\\n@@@5. Remove same multiple urls in expanded_urls variable \\n@@@6. Change the rating denominator to 10\\n@@@7. Remove non name characters from the name variable\\n@@@8. Only keep necessary columns\\n@@@\\n@@@#### Cleaning image_predictions table\\n@@@1. Drop img_num variable\\n@@@\\n@@@#### Cleaning json tweets table\\n@@@1. Drop full_text and time_created variables\\n@@@\\n@@@### Define - Structural Issues\\n@@@1. Merge cleaned twitter archive table with cleaned image predictions table to create a df_main table\\n@@@2. Merge the df_main table with cleaned json tweets table\\n@@@3. For df_main dataframe, merge  \\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\' variables into one column \\n@@@\\n@@@## Cleaning the twitter_archive dataframe \\n@@@\\n@@@\\n@@@```python\\n@@@# make a copy of the twitter_archive dataframe\\n@@@df_twitter_archive_clean=df_twitter_archive.copy()\\n@@@```\\n@@@\\n@@@\\n@@@```python\\n@@@# 1. Format the timestamp to datetime format\\n@@@\\n@@@#### code\\n@@@# remove the +0000 from timestamp\\n@@@df_twitter_archive_clean.timestamp=df_twitter_archive_clean.timestamp.str[:-6]\\n@@@\\n@@@# convert the whole column proper date format using the datetime function\\n@@@df_twitter_archive_clean[\\'timestamp\\'] =  pd.to_datetime(df_twitter_archive_clean[\\'timestamp\\'], format=\\'%Y-%m-%d %X\\')\\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    RangeIndex: 2356 entries, 0 to 2355\\n@@@    Data columns (total 17 columns):\\n@@@    tweet_id                      2356 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2356 non-null datetime64[ns]\\n@@@    source                        2356 non-null object\\n@@@    text                          2356 non-null object\\n@@@    retweeted_status_id           181 non-null float64\\n@@@    retweeted_status_user_id      181 non-null float64\\n@@@    retweeted_status_timestamp    181 non-null object\\n@@@    expanded_urls                 2297 non-null object\\n@@@    rating_numerator              2356 non-null int64\\n@@@    rating_denominator            2356 non-null int64\\n@@@    name                          2356 non-null object\\n@@@    doggo                         2356 non-null object\\n@@@    floofer                       2356 non-null object\\n@@@    pupper                        2356 non-null object\\n@@@    puppo                         2356 non-null object\\n@@@    dtypes: datetime64[ns](1), float64(4), int64(3), object(9)\\n@@@    memory usage: 313.0+ KB\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 2. Add columns for the month, weekday and hour the tweet was created\\n@@@\\n@@@#### code\\n@@@#df_twitter_clean.timestamp[0].hour\\n@@@df_twitter_archive_clean[\\'timestamp_month\\']=df_twitter_archive_clean.timestamp.map(lambda a: a.month)\\n@@@df_twitter_archive_clean[\\'timestamp_weekday\\']=df_twitter_archive_clean.timestamp.map(lambda a: a.weekday())\\n@@@df_twitter_archive_clean[\\'timestamp_hour\\']=df_twitter_archive_clean.timestamp.map(lambda a: a.hour)\\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>in_reply_to_status_id</th>\\n@@@      <th>in_reply_to_user_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>retweeted_status_id</th>\\n@@@      <th>retweeted_status_user_id</th>\\n@@@      <th>retweeted_status_timestamp</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@      <th>timestamp_month</th>\\n@@@      <th>timestamp_weekday</th>\\n@@@      <th>timestamp_hour</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>16</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>NaN</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>0</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# 3. Remove all retweets\\n@@@# retweeted_status_id contains id of retweets so remove all retweets and only keep NaN\\n@@@\\n@@@#### code\\n@@@# df_twitter_clean.retweeted_status_id\\n@@@index_original_tweet=pd.isnull(df_twitter_archive_clean[\\'retweeted_status_id\\'])\\n@@@df_twitter_archive_clean=df_twitter_archive_clean[index_original_tweet]\\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.retweeted_status_id.value_counts() # shows no values\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    Series([], Name: retweeted_status_id, dtype: int64)\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# 4. Convert source to categorical value\\n@@@\\n@@@#### code\\n@@@#view the value counts\\n@@@print(df_twitter_archive_clean.source.value_counts())\\n@@@\\n@@@\\n@@@# create a dictionary for mapping\\n@@@di_source = {\\'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\\':\\'Twitter for iPhone\\',\\n@@@            \\'<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>\\':\\'Vine - Make a Scene\\',\\n@@@            \\'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>\\':\\'Twitter Web Client\\',\\n@@@            \\'<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>\\':\\'TweetDeck\\'}\\n@@@\\n@@@# map the dictionary \\n@@@df_twitter_archive_clean[\\'source\\']=df_twitter_archive_clean[\\'source\\'].replace(di_source)\\n@@@\\n@@@print(\\'\\\\n\\\\n\\')\\n@@@print(df_twitter_archive_clean[\\'source\\'].value_counts())\\n@@@print(\\'\\\\n\\\\n\\')\\n@@@\\n@@@# convert the source variable to a categorical object\\n@@@df_twitter_archive_clean[\\'source\\']=df_twitter_archive_clean[\\'source\\'].astype(\\'category\\')\\n@@@\\n@@@#### test \\n@@@# .info() hows that source variable is now sa category \\n@@@print(df_twitter_archive_clean.info())\\n@@@```\\n@@@\\n@@@    <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>     2042\\n@@@    <a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>                          91\\n@@@    <a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>                       31\\n@@@    <a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>      11\\n@@@    Name: source, dtype: int64\\n@@@    \\n@@@    \\n@@@    \\n@@@    Twitter for iPhone     2042\\n@@@    Vine - Make a Scene      91\\n@@@    Twitter Web Client       31\\n@@@    TweetDeck                11\\n@@@    Name: source, dtype: int64\\n@@@    \\n@@@    \\n@@@    \\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    Int64Index: 2175 entries, 0 to 2355\\n@@@    Data columns (total 20 columns):\\n@@@    tweet_id                      2175 non-null int64\\n@@@    in_reply_to_status_id         78 non-null float64\\n@@@    in_reply_to_user_id           78 non-null float64\\n@@@    timestamp                     2175 non-null datetime64[ns]\\n@@@    source                        2175 non-null category\\n@@@    text                          2175 non-null object\\n@@@    retweeted_status_id           0 non-null float64\\n@@@    retweeted_status_user_id      0 non-null float64\\n@@@    retweeted_status_timestamp    0 non-null object\\n@@@    expanded_urls                 2117 non-null object\\n@@@    rating_numerator              2175 non-null int64\\n@@@    rating_denominator            2175 non-null int64\\n@@@    name                          2175 non-null object\\n@@@    doggo                         2175 non-null object\\n@@@    floofer                       2175 non-null object\\n@@@    pupper                        2175 non-null object\\n@@@    puppo                         2175 non-null object\\n@@@    timestamp_month               2175 non-null int64\\n@@@    timestamp_weekday             2175 non-null int64\\n@@@    timestamp_hour                2175 non-null int64\\n@@@    dtypes: category(1), datetime64[ns](1), float64(4), int64(6), object(8)\\n@@@    memory usage: 342.2+ KB\\n@@@    None\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 5. Remove same multiple urls in expanded_urls variable \\n@@@\\n@@@#### code\\n@@@# first print the urls to screen\\n@@@df_twitter_archive_clean.expanded_urls.head(10).map(lambda a : print(a))\\n@@@```\\n@@@\\n@@@    https://twitter.com/dog_rates/status/892420643555336193/photo/1\\n@@@    https://twitter.com/dog_rates/status/892177421306343426/photo/1\\n@@@    https://twitter.com/dog_rates/status/891815181378084864/photo/1\\n@@@    https://twitter.com/dog_rates/status/891689557279858688/photo/1\\n@@@    https://twitter.com/dog_rates/status/891327558926688256/photo/1,https://twitter.com/dog_rates/status/891327558926688256/photo/1\\n@@@    https://twitter.com/dog_rates/status/891087950875897856/photo/1\\n@@@    https://gofundme.com/ydvmve-surgery-for-jax,https://twitter.com/dog_rates/status/890971913173991426/photo/1\\n@@@    https://twitter.com/dog_rates/status/890729181411237888/photo/1,https://twitter.com/dog_rates/status/890729181411237888/photo/1\\n@@@    https://twitter.com/dog_rates/status/890609185150312448/photo/1\\n@@@    https://twitter.com/dog_rates/status/890240255349198849/photo/1\\n@@@    \\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    0    None\\n@@@    1    None\\n@@@    2    None\\n@@@    3    None\\n@@@    4    None\\n@@@    5    None\\n@@@    6    None\\n@@@    7    None\\n@@@    8    None\\n@@@    9    None\\n@@@    Name: expanded_urls, dtype: object\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@#### code continued..\\n@@@# use the str.split function to split on comma and save the first column\\n@@@tmp=df_twitter_archive_clean.expanded_urls.str.split(\\',\\', expand=True)[0]\\n@@@#tmp.map(lambda a : print(a))\\n@@@\\n@@@\\n@@@#### test \\n@@@# print the formatted urp to screen for a visual confirmation\\n@@@df_twitter_archive_clean.expanded_urls=tmp.copy()\\n@@@df_twitter_archive_clean.expanded_urls.head(10).map(lambda a : print(a))\\n@@@```\\n@@@\\n@@@    https://twitter.com/dog_rates/status/892420643555336193/photo/1\\n@@@    https://twitter.com/dog_rates/status/892177421306343426/photo/1\\n@@@    https://twitter.com/dog_rates/status/891815181378084864/photo/1\\n@@@    https://twitter.com/dog_rates/status/891689557279858688/photo/1\\n@@@    https://twitter.com/dog_rates/status/891327558926688256/photo/1\\n@@@    https://twitter.com/dog_rates/status/891087950875897856/photo/1\\n@@@    https://gofundme.com/ydvmve-surgery-for-jax\\n@@@    https://twitter.com/dog_rates/status/890729181411237888/photo/1\\n@@@    https://twitter.com/dog_rates/status/890609185150312448/photo/1\\n@@@    https://twitter.com/dog_rates/status/890240255349198849/photo/1\\n@@@    \\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    0    None\\n@@@    1    None\\n@@@    2    None\\n@@@    3    None\\n@@@    4    None\\n@@@    5    None\\n@@@    6    None\\n@@@    7    None\\n@@@    8    None\\n@@@    9    None\\n@@@    Name: expanded_urls, dtype: object\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@# 6. Change the rating denominator to 10\\n@@@\\n@@@#### code\\n@@@print(df_twitter_archive_clean.rating_denominator.value_counts())\\n@@@df_twitter_archive_clean.rating_denominator=10\\n@@@\\n@@@#### test\\n@@@print(\\'\\\\n\\\\n\\')\\n@@@print(df_twitter_archive_clean.rating_denominator.value_counts())\\n@@@\\n@@@```\\n@@@\\n@@@    10     2153\\n@@@    50        3\\n@@@    80        2\\n@@@    11        2\\n@@@    20        2\\n@@@    2         1\\n@@@    16        1\\n@@@    40        1\\n@@@    70        1\\n@@@    15        1\\n@@@    90        1\\n@@@    110       1\\n@@@    120       1\\n@@@    130       1\\n@@@    150       1\\n@@@    170       1\\n@@@    7         1\\n@@@    0         1\\n@@@    Name: rating_denominator, dtype: int64\\n@@@    \\n@@@    \\n@@@    \\n@@@    10    2175\\n@@@    Name: rating_denominator, dtype: int64\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 7. Remove non name characters from the name variable\\n@@@# Replace the non name strings \\'None\\',\\'a\\', \\'an\\' with Nan\\n@@@\\n@@@#### code\\n@@@print(df_twitter_archive_clean.name.value_counts()) # shows there is None,a,an in name value \\n@@@```\\n@@@\\n@@@    None         680\\n@@@    a             55\\n@@@    Charlie       11\\n@@@    Lucy          11\\n@@@    Cooper        10\\n@@@    Oliver        10\\n@@@    Penny          9\\n@@@    Tucker         9\\n@@@    Sadie          8\\n@@@    the            8\\n@@@    Winston        8\\n@@@    Lola           8\\n@@@    Daisy          7\\n@@@    Toby           7\\n@@@    Bailey         6\\n@@@    Jax            6\\n@@@    Bo             6\\n@@@    Koda           6\\n@@@    Stanley        6\\n@@@    Bella          6\\n@@@    Oscar          6\\n@@@    an             6\\n@@@    Dave           5\\n@@@    Milo           5\\n@@@    Bentley        5\\n@@@    Rusty          5\\n@@@    Buddy          5\\n@@@    Louis          5\\n@@@    Chester        5\\n@@@    Leo            5\\n@@@                ... \\n@@@    Levi           1\\n@@@    Aubie          1\\n@@@    Asher          1\\n@@@    Shnuggles      1\\n@@@    Amber          1\\n@@@    Astrid         1\\n@@@    Beemo          1\\n@@@    Aldrick        1\\n@@@    Julio          1\\n@@@    Laika          1\\n@@@    Chef           1\\n@@@    Sandra         1\\n@@@    Eve            1\\n@@@    Newt           1\\n@@@    Zeek           1\\n@@@    Filup          1\\n@@@    Hubertson      1\\n@@@    Sierra         1\\n@@@    Alf            1\\n@@@    Skittle        1\\n@@@    Charleson      1\\n@@@    Tedrick        1\\n@@@    Steve          1\\n@@@    Hanz           1\\n@@@    Akumi          1\\n@@@    Wafer          1\\n@@@    Happy          1\\n@@@    Angel          1\\n@@@    Benny          1\\n@@@    such           1\\n@@@    Name: name, Length: 956, dtype: int64\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@#### code continued ...\\n@@@# Try using Regex for a one liner\\n@@@#Replace \\'None\\' with Nan\\n@@@df_twitter_archive_clean[\\'name\\']=df_twitter_archive_clean[\\'name\\'].replace(\\'None\\', np.NaN, )\\n@@@# Replace \\'a\\' with Nan\\n@@@df_twitter_archive_clean[\\'name\\']=df_twitter_archive_clean[\\'name\\'].replace(\\'a\\', np.NaN, )\\n@@@# Replace \\'an\\' with Nan\\n@@@df_twitter_archive_clean[\\'name\\']=df_twitter_archive_clean[\\'name\\'].replace(\\'an\\', np.NaN, )\\n@@@\\n@@@#### test\\n@@@print(df_twitter_archive_clean[\\'name\\'].value_counts())\\n@@@# output shows no occurance of None, a, an\\n@@@```\\n@@@\\n@@@    Lucy         11\\n@@@    Charlie      11\\n@@@    Cooper       10\\n@@@    Oliver       10\\n@@@    Tucker        9\\n@@@    Penny         9\\n@@@    Winston       8\\n@@@    Lola          8\\n@@@    Sadie         8\\n@@@    the           8\\n@@@    Daisy         7\\n@@@    Toby          7\\n@@@    Jax           6\\n@@@    Koda          6\\n@@@    Bella         6\\n@@@    Oscar         6\\n@@@    Bailey        6\\n@@@    Bo            6\\n@@@    Stanley       6\\n@@@    Rusty         5\\n@@@    Chester       5\\n@@@    Buddy         5\\n@@@    Scout         5\\n@@@    Leo           5\\n@@@    Louis         5\\n@@@    Milo          5\\n@@@    Bentley       5\\n@@@    Dave          5\\n@@@    Jack          4\\n@@@    Archie        4\\n@@@                 ..\\n@@@    Mimosa        1\\n@@@    Levi          1\\n@@@    Aubie         1\\n@@@    Asher         1\\n@@@    Aldrick       1\\n@@@    Benny         1\\n@@@    Angel         1\\n@@@    Happy         1\\n@@@    Diogi         1\\n@@@    Trigger       1\\n@@@    Antony        1\\n@@@    Julio         1\\n@@@    Laika         1\\n@@@    Chef          1\\n@@@    Sandra        1\\n@@@    Eve           1\\n@@@    Newt          1\\n@@@    Zeek          1\\n@@@    Filup         1\\n@@@    Hubertson     1\\n@@@    Sierra        1\\n@@@    Alf           1\\n@@@    Skittle       1\\n@@@    Charleson     1\\n@@@    Tedrick       1\\n@@@    Steve         1\\n@@@    Hanz          1\\n@@@    Akumi         1\\n@@@    Wafer         1\\n@@@    such          1\\n@@@    Name: name, Length: 953, dtype: int64\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# 8. Only keep necessary columns\\n@@@# Drop the following columns : \\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'retweeted_status_id\\', \\n@@@#                              \\'retweeted_status_user_id\\',\\'retweeted_status_timestamp\\'\\n@@@\\n@@@#### code\\n@@@print(df_twitter_archive_clean.columns)\\n@@@\\n@@@drop_columns = [\\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'retweeted_status_id\\', \\n@@@                \\'retweeted_status_user_id\\',\\'retweeted_status_timestamp\\']\\n@@@\\n@@@df_twitter_archive_clean=df_twitter_archive_clean.drop(drop_columns, axis=1)  # df.columns is zero-based pd.Index \\n@@@\\n@@@#### test\\n@@@df_twitter_archive_clean.head()\\n@@@```\\n@@@\\n@@@    Index([\\'tweet_id\\', \\'in_reply_to_status_id\\', \\'in_reply_to_user_id\\', \\'timestamp\\',\\n@@@           \\'source\\', \\'text\\', \\'retweeted_status_id\\', \\'retweeted_status_user_id\\',\\n@@@           \\'retweeted_status_timestamp\\', \\'expanded_urls\\', \\'rating_numerator\\',\\n@@@           \\'rating_denominator\\', \\'name\\', \\'doggo\\', \\'floofer\\', \\'pupper\\', \\'puppo\\',\\n@@@           \\'timestamp_month\\', \\'timestamp_weekday\\', \\'timestamp_hour\\'],\\n@@@          dtype=\\'object\\')\\n@@@    \\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>pupper</th>\\n@@@      <th>puppo</th>\\n@@@      <th>timestamp_month</th>\\n@@@      <th>timestamp_weekday</th>\\n@@@      <th>timestamp_hour</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>16</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>0</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>2017-07-31 00:18:03</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/891815181...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>Archie</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>7</td>\\n@@@      <td>0</td>\\n@@@      <td>0</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>2017-07-30 15:58:51</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Darla. She commenced a snooze mid meal...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/891689557...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Darla</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>7</td>\\n@@@      <td>6</td>\\n@@@      <td>15</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>2017-07-29 16:00:24</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Franklin. He would like you to stop ca...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/891327558...</td>\\n@@@      <td>12</td>\\n@@@      <td>10</td>\\n@@@      <td>Franklin</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>7</td>\\n@@@      <td>5</td>\\n@@@      <td>16</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Clean image_predictions table\\n@@@\\n@@@\\n@@@```python\\n@@@# 1. Drop img_num variable\\n@@@\\n@@@#### code\\n@@@df_image_predictions_clean=df_image_predictions.copy()\\n@@@#df_image_predictions_clean.head()\\n@@@df_image_predictions_clean=df_image_predictions_clean.drop(\\'img_num\\',axis=1)\\n@@@\\n@@@#### test\\n@@@df_image_predictions_clean.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>666020888022790149</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\\n@@@      <td>Welsh_springer_spaniel</td>\\n@@@      <td>0.465074</td>\\n@@@      <td>True</td>\\n@@@      <td>collie</td>\\n@@@      <td>0.156665</td>\\n@@@      <td>True</td>\\n@@@      <td>Shetland_sheepdog</td>\\n@@@      <td>0.061428</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>666029285002620928</td>\\n@@@      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.506826</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.074192</td>\\n@@@      <td>True</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.072010</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>666033412701032449</td>\\n@@@      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\\n@@@      <td>German_shepherd</td>\\n@@@      <td>0.596461</td>\\n@@@      <td>True</td>\\n@@@      <td>malinois</td>\\n@@@      <td>0.138584</td>\\n@@@      <td>True</td>\\n@@@      <td>bloodhound</td>\\n@@@      <td>0.116197</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>666044226329800704</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\\n@@@      <td>Rhodesian_ridgeback</td>\\n@@@      <td>0.408143</td>\\n@@@      <td>True</td>\\n@@@      <td>redbone</td>\\n@@@      <td>0.360687</td>\\n@@@      <td>True</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.222752</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>666049248165822465</td>\\n@@@      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\\n@@@      <td>miniature_pinscher</td>\\n@@@      <td>0.560311</td>\\n@@@      <td>True</td>\\n@@@      <td>Rottweiler</td>\\n@@@      <td>0.243682</td>\\n@@@      <td>True</td>\\n@@@      <td>Doberman</td>\\n@@@      <td>0.154629</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Clean json tweets table\\n@@@\\n@@@\\n@@@```python\\n@@@# 1. Drop full_text and time_created variables\\n@@@\\n@@@#### code\\n@@@df_json_tweets_cleaned=df_json_tweets.copy()\\n@@@drop_columns=[\\'full_text\\',\\'time_created\\']\\n@@@df_json_tweets_cleaned=df_json_tweets_cleaned.drop(drop_columns,axis=1)\\n@@@\\n@@@#### test\\n@@@df_json_tweets_cleaned.head()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>38492</td>\\n@@@      <td>8480</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>32986</td>\\n@@@      <td>6241</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>2</th>\\n@@@      <td>891815181378084864</td>\\n@@@      <td>24840</td>\\n@@@      <td>4137</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>3</th>\\n@@@      <td>891689557279858688</td>\\n@@@      <td>41865</td>\\n@@@      <td>8598</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>4</th>\\n@@@      <td>891327558926688256</td>\\n@@@      <td>40029</td>\\n@@@      <td>9336</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Structural Issue 1: Merge cleaned twitter archive table with cleaned image predictions table to create a df_main table\\n@@@\\n@@@\\n@@@```python\\n@@@# Structural Issue 1: Merge cleaned twitter archive table with cleaned image predictions table to create a df_main table\\n@@@\\n@@@#### code\\n@@@df_main=pd.merge(df_twitter_archive_clean,df_image_predictions_clean, on=\\'tweet_id\\', how=\\'left\\')\\n@@@\\n@@@#### test\\n@@@df_main.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>doggo</th>\\n@@@      <th>floofer</th>\\n@@@      <th>...</th>\\n@@@      <th>jpg_url</th>\\n@@@      <th>p1</th>\\n@@@      <th>p1_conf</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>...</td>\\n@@@      <td>https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg</td>\\n@@@      <td>orange</td>\\n@@@      <td>0.097049</td>\\n@@@      <td>False</td>\\n@@@      <td>bagel</td>\\n@@@      <td>0.085851</td>\\n@@@      <td>False</td>\\n@@@      <td>banana</td>\\n@@@      <td>0.076110</td>\\n@@@      <td>False</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>None</td>\\n@@@      <td>None</td>\\n@@@      <td>...</td>\\n@@@      <td>https://pbs.twimg.com/media/DGGmoV4XsAAUL6n.jpg</td>\\n@@@      <td>Chihuahua</td>\\n@@@      <td>0.323581</td>\\n@@@      <td>True</td>\\n@@@      <td>Pekinese</td>\\n@@@      <td>0.090647</td>\\n@@@      <td>True</td>\\n@@@      <td>papillon</td>\\n@@@      <td>0.068957</td>\\n@@@      <td>True</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@<p>2 rows Ã— 25 columns</p>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@# Structural Issue 2: Merge the df_main table with cleaned json tweets table\\n@@@\\n@@@\\n@@@```python\\n@@@# Structural Issue 2: Merge the df_main table with cleaned json tweets table\\n@@@\\n@@@#### code\\n@@@df_main=pd.merge(df_main,df_json_tweets_cleaned,on=\\'tweet_id\\', how=\\'left\\')\\n@@@\\n@@@#### test\\n@@@df_main.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    Int64Index: 2175 entries, 0 to 2174\\n@@@    Data columns (total 27 columns):\\n@@@    tweet_id              2175 non-null int64\\n@@@    timestamp             2175 non-null datetime64[ns]\\n@@@    source                2175 non-null category\\n@@@    text                  2175 non-null object\\n@@@    expanded_urls         2117 non-null object\\n@@@    rating_numerator      2175 non-null int64\\n@@@    rating_denominator    2175 non-null int64\\n@@@    name                  1434 non-null object\\n@@@    doggo                 2175 non-null object\\n@@@    floofer               2175 non-null object\\n@@@    pupper                2175 non-null object\\n@@@    puppo                 2175 non-null object\\n@@@    timestamp_month       2175 non-null int64\\n@@@    timestamp_weekday     2175 non-null int64\\n@@@    timestamp_hour        2175 non-null int64\\n@@@    jpg_url               1994 non-null object\\n@@@    p1                    1994 non-null object\\n@@@    p1_conf               1994 non-null float64\\n@@@    p1_dog                1994 non-null object\\n@@@    p2                    1994 non-null object\\n@@@    p2_conf               1994 non-null float64\\n@@@    p2_dog                1994 non-null object\\n@@@    p3                    1994 non-null object\\n@@@    p3_conf               1994 non-null float64\\n@@@    p3_dog                1994 non-null object\\n@@@    favorite_count        2174 non-null float64\\n@@@    retweet_count         2174 non-null float64\\n@@@    dtypes: category(1), datetime64[ns](1), float64(5), int64(6), object(14)\\n@@@    memory usage: 461.1+ KB\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@\\n@@@```\\n@@@\\n@@@# Structural Issue 3: For df_main dataframe, merge  \\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\' variables into one column \\n@@@\\n@@@\\n@@@```python\\n@@@# Structural Issue 3: melt variables \\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\' into one column\\n@@@\\n@@@#### code\\n@@@# copy the variables to a tmp dataframe\\n@@@tmp=df_main[[\\'tweet_id\\',\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\']].copy()\\n@@@\\n@@@# melt the variables\\n@@@tmp=pd.melt(tmp,id_vars=[\\'tweet_id\\'], value_vars=[\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\'],value_name=\\'growth_stage\\')\\n@@@\\n@@@# drop the column called variable\\n@@@tmp=tmp.drop(\\'variable\\', axis=1)\\n@@@\\n@@@# replace the None with NaN in growth_stage column\\n@@@tmp[\\'growth_stage\\']=tmp[\\'growth_stage\\'].replace(\\'None\\', np.NaN, )\\n@@@\\n@@@#drop rows containing na\\'s because there are too many rows with na\\'s\\n@@@tmp=tmp.dropna()\\n@@@\\n@@@tmp.growth_stage.value_counts()\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@    pupper     234\\n@@@    doggo       87\\n@@@    puppo       25\\n@@@    floofer     10\\n@@@    Name: growth_stage, dtype: int64\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@#### code continued ...\\n@@@# remove the following variables (\\'tweet_id\\',\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\') from the df_main table\\n@@@drop_columns = [\\'doggo\\',\\'floofer\\',\\'pupper\\',\\'puppo\\']\\n@@@df_main = df_main.drop(drop_columns,axis=1)\\n@@@\\n@@@# merge df_main with the tmp dataframe containing the growth_stage column\\n@@@df_main=pd.merge(df_main,tmp,on=\\'tweet_id\\', how=\\'left\\')\\n@@@\\n@@@df_main.head(2)\\n@@@```\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@<div>\\n@@@<style scoped>\\n@@@    .dataframe tbody tr th:only-of-type {\\n@@@        vertical-align: middle;\\n@@@    }\\n@@@\\n@@@    .dataframe tbody tr th {\\n@@@        vertical-align: top;\\n@@@    }\\n@@@\\n@@@    .dataframe thead th {\\n@@@        text-align: right;\\n@@@    }\\n@@@</style>\\n@@@<table border=\"1\" class=\"dataframe\">\\n@@@  <thead>\\n@@@    <tr style=\"text-align: right;\">\\n@@@      <th></th>\\n@@@      <th>tweet_id</th>\\n@@@      <th>timestamp</th>\\n@@@      <th>source</th>\\n@@@      <th>text</th>\\n@@@      <th>expanded_urls</th>\\n@@@      <th>rating_numerator</th>\\n@@@      <th>rating_denominator</th>\\n@@@      <th>name</th>\\n@@@      <th>timestamp_month</th>\\n@@@      <th>timestamp_weekday</th>\\n@@@      <th>...</th>\\n@@@      <th>p1_dog</th>\\n@@@      <th>p2</th>\\n@@@      <th>p2_conf</th>\\n@@@      <th>p2_dog</th>\\n@@@      <th>p3</th>\\n@@@      <th>p3_conf</th>\\n@@@      <th>p3_dog</th>\\n@@@      <th>favorite_count</th>\\n@@@      <th>retweet_count</th>\\n@@@      <th>growth_stage</th>\\n@@@    </tr>\\n@@@  </thead>\\n@@@  <tbody>\\n@@@    <tr>\\n@@@      <th>0</th>\\n@@@      <td>892420643555336193</td>\\n@@@      <td>2017-08-01 16:23:56</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Phineas. He\\'s a mystical boy. Only eve...</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892420643...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Phineas</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>...</td>\\n@@@      <td>False</td>\\n@@@      <td>bagel</td>\\n@@@      <td>0.085851</td>\\n@@@      <td>False</td>\\n@@@      <td>banana</td>\\n@@@      <td>0.076110</td>\\n@@@      <td>False</td>\\n@@@      <td>38492.0</td>\\n@@@      <td>8480.0</td>\\n@@@      <td>NaN</td>\\n@@@    </tr>\\n@@@    <tr>\\n@@@      <th>1</th>\\n@@@      <td>892177421306343426</td>\\n@@@      <td>2017-08-01 00:17:27</td>\\n@@@      <td>Twitter for iPhone</td>\\n@@@      <td>This is Tilly. She\\'s just checking pup on you....</td>\\n@@@      <td>https://twitter.com/dog_rates/status/892177421...</td>\\n@@@      <td>13</td>\\n@@@      <td>10</td>\\n@@@      <td>Tilly</td>\\n@@@      <td>8</td>\\n@@@      <td>1</td>\\n@@@      <td>...</td>\\n@@@      <td>True</td>\\n@@@      <td>Pekinese</td>\\n@@@      <td>0.090647</td>\\n@@@      <td>True</td>\\n@@@      <td>papillon</td>\\n@@@      <td>0.068957</td>\\n@@@      <td>True</td>\\n@@@      <td>32986.0</td>\\n@@@      <td>6241.0</td>\\n@@@      <td>NaN</td>\\n@@@    </tr>\\n@@@  </tbody>\\n@@@</table>\\n@@@<p>2 rows Ã— 24 columns</p>\\n@@@</div>\\n@@@\\n@@@\\n@@@\\n@@@\\n@@@```python\\n@@@#### test\\n@@@df_main.info()\\n@@@```\\n@@@\\n@@@    <class \\'pandas.core.frame.DataFrame\\'>\\n@@@    Int64Index: 2187 entries, 0 to 2186\\n@@@    Data columns (total 24 columns):\\n@@@    tweet_id              2187 non-null int64\\n@@@    timestamp             2187 non-null datetime64[ns]\\n@@@    source                2187 non-null category\\n@@@    text                  2187 non-null object\\n@@@    expanded_urls         2129 non-null object\\n@@@    rating_numerator      2187 non-null int64\\n@@@    rating_denominator    2187 non-null int64\\n@@@    name                  1439 non-null object\\n@@@    timestamp_month       2187 non-null int64\\n@@@    timestamp_weekday     2187 non-null int64\\n@@@    timestamp_hour        2187 non-null int64\\n@@@    jpg_url               2005 non-null object\\n@@@    p1                    2005 non-null object\\n@@@    p1_conf               2005 non-null float64\\n@@@    p1_dog                2005 non-null object\\n@@@    p2                    2005 non-null object\\n@@@    p2_conf               2005 non-null float64\\n@@@    p2_dog                2005 non-null object\\n@@@    p3                    2005 non-null object\\n@@@    p3_conf               2005 non-null float64\\n@@@    p3_dog                2005 non-null object\\n@@@    favorite_count        2186 non-null float64\\n@@@    retweet_count         2186 non-null float64\\n@@@    growth_stage          356 non-null object\\n@@@    dtypes: category(1), datetime64[ns](1), float64(5), int64(6), object(11)\\n@@@    memory usage: 412.4+ KB\\n@@@    \\n@@@\\n@@@\\n@@@```python\\n@@@# save the main dataframe to working directory\\n@@@df_main.to_csv(\\'main_twitter_dataset.csv\\', index=False)\\n@@@```\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this below to split at @@@ and then save it to a md file\n",
    "lines=content_joined.split('@@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use this to write the files back\n",
    "with open(markdown_name, 'w') as filehandle:  \n",
    "    filehandle.writelines(\"%s\" % place for place in lines)\n",
    "    #code below will add a line break\n",
    "    #filehandle.writelines(\"%s\\n\" % place for place in places_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a795cf9fc51d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#define source and destination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_folder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdestination\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'git_page/images/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msubfolder_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0_files'"
     ]
    }
   ],
   "source": [
    "#copy image files to the images/movie_data_eda subfoler\n",
    "\n",
    "#define source and destination\n",
    "source=os.listdir(images_folder_name)\n",
    "destination='git_page/images/'+subfolder_name\n",
    "\n",
    "\n",
    "#works\n",
    "for files in source:\n",
    "    if files.endswith(\".png\"):\n",
    "        shutil.copy(images_folder_name+'/'+files,destination)\n",
    "        #print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'git_page/data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0.md'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy md file to git_page folder\n",
    "#source='markdown/project_03_01.md'\n",
    "#destination='git_page/'\n",
    "#shutil.copy(source, destination)\n",
    "\n",
    "source=markdown_name\n",
    "destination='git_page/'\n",
    "shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-941f67ec5233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#delete the images folder that is OUTSIDE the git_page folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_folder_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#remove folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#delete the markdonw file that is OUTSIDE the git_page folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkdown_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#remove file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mfullname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data_analyst_nanodegree_term_02_project_03_wrangle_act_v2_0_files'"
     ]
    }
   ],
   "source": [
    "#delete the images folder that is OUTSIDE the git_page folder\n",
    "shutil.rmtree(images_folder_name) #remove folder\n",
    "#delete the markdonw file that is OUTSIDE the git_page folder\n",
    "os.remove(markdown_name) #remove file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
